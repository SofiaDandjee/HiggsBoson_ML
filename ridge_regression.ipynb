{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "S_s6B33VEndZ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# Useful starting lines\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YaBZH_VLEndi"
   },
   "source": [
    "## Load the training data into feature matrix, class labels, and event ids:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QUp3aGWvqm3j"
   },
   "outputs": [],
   "source": [
    "from proj1_helpers import *\n",
    "from implementations import *\n",
    "from data_helpers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pgWxh_GdEndl"
   },
   "outputs": [],
   "source": [
    "#DATA_TRAIN_PATH = '/content/drive/My Drive/ML_Project1/data/train.csv'\n",
    "DATA_TRAIN_PATH = 'data/train.csv' # TODO: download train data and supply path here \n",
    "y, tX, ids = load_csv_data(DATA_TRAIN_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DATA PREPROCESSING : we try to limit the number of undefined values appearing in the datas \n",
    "bounds = [0.1, 0.5]   \n",
    "tX, indices = treat_undefined_values(bounds, tX) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MODEL BUILDING\n",
    "tx, mean, std = standardize(tX,0)\n",
    "y, tx = build_model_data(tx,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratio = 0.9\n",
    "\n",
    "train_x, train_y, test_x, test_y = split_data(tx, y, ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-jv3lZU9hlEw",
    "outputId": "fd436073-e0fd-40c4-efb2-bdae44420cbf"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((225000, 24), (225000,), (25000, 24), (25000,))"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x.shape, train_y.shape, test_x.shape, test_y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ReKwkQ-cEnds"
   },
   "source": [
    "## Do your thing crazy machine learning thing here :) ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 232
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 544,
     "status": "error",
     "timestamp": 1571295874514,
     "user": {
      "displayName": "Sofia Dandjee",
      "photoUrl": "",
      "userId": "04011238111956572445"
     },
     "user_tz": -120
    },
    "id": "b2HFZUfIxCgX",
    "outputId": "eea2b54a-30c0-4fc8-ef35-8cf93c297fb4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lambda=1e-05, Training Loss =0.35194586854977816, Validation Loss =0.3541886198766681\n",
      "Lambda=1.8329807108324375e-05, Training Loss =0.3519458868550372, Validation Loss =0.35418841161547626\n",
      "Lambda=3.359818286283781e-05, Training Loss =0.3519459200022886, Validation Loss =0.35418830488424385\n",
      "Lambda=6.158482110660267e-05, Training Loss =0.35194598062599014, Validation Loss =0.3541884648492717\n",
      "Lambda=0.00011288378916846884, Training Loss =0.3519461157654936, Validation Loss =0.35418912297452027\n",
      "Lambda=0.00020691380811147902, Training Loss =0.3519464817451982, Validation Loss =0.3541906533934322\n",
      "Lambda=0.000379269019073225, Training Loss =0.3519475346764282, Validation Loss =0.3541937682149088\n",
      "Lambda=0.0006951927961775605, Training Loss =0.3519505164887544, Validation Loss =0.3541999580445266\n",
      "Lambda=0.0012742749857031334, Training Loss =0.3519588060589998, Validation Loss =0.3542127710362081\n",
      "Lambda=0.002335721469090121, Training Loss =0.35198217492750494, Validation Loss =0.3542421485356522\n",
      "Lambda=0.004281332398719391, Training Loss =0.3520497852107563, Validation Loss =0.3543177749478102\n",
      "Lambda=0.007847599703514606, Training Loss =0.35224344683593994, Validation Loss =0.35452260241668804\n",
      "Lambda=0.01438449888287663, Training Loss =0.352762066016089, Validation Loss =0.35505653986989205\n",
      "Lambda=0.026366508987303583, Training Loss =0.35399316036047457, Validation Loss =0.356304470032871\n",
      "Lambda=0.04832930238571752, Training Loss =0.3564913124413275, Validation Loss =0.3588066642185855\n",
      "Lambda=0.08858667904100823, Training Loss =0.3608308783455325, Validation Loss =0.36310247459299544\n",
      "Lambda=0.1623776739188721, Training Loss =0.3676394433411952, Validation Loss =0.36976786987274085\n",
      "Lambda=0.2976351441631319, Training Loss =0.37792645165000605, Validation Loss =0.3797729160964638\n",
      "Lambda=0.5455594781168515, Training Loss =0.39276749064900496, Validation Loss =0.3942049043072271\n",
      "Lambda=1.0, Training Loss =0.4118551414149711, Validation Loss =0.41283141260983813\n",
      "3.359818286283781e-05\n",
      "(250000, 23)\n"
     ]
    }
   ],
   "source": [
    "lambdas = np.logspace(-5,0,20)\n",
    "\n",
    "loss_min = np.inf\n",
    "\n",
    "for _,lambda_ in enumerate(lambdas):\n",
    "\n",
    "    weights,loss_training = ridge_regression(train_y, train_x, lambda_)\n",
    "    loss_validation = compute_loss(test_y, test_x, weights)\n",
    "    print(\"Lambda={l}, Training Loss ={tl}, Validation Loss ={vl}\".format(\n",
    "               l=lambda_, tl=loss_training, vl=loss_validation))\n",
    "    \n",
    "    if (loss_validation < loss_min):\n",
    "        \n",
    "        loss_min = loss_validation\n",
    "        lambda_min = lambda_\n",
    "        weights_star = weights\n",
    "print(lambda_min)\n",
    "print(tX.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yUQybl2IEndu"
   },
   "source": [
    "## Generate predictions and save ouput in csv format for submission:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ewy_ZY2kEndx"
   },
   "outputs": [],
   "source": [
    "DATA_TEST_PATH = 'data/test.csv' # TODO: download train data and supply path here \n",
    "ytest, tX_test, ids_test = load_csv_data(DATA_TEST_PATH)\n",
    "tX_test = np.delete(tX_test, indices, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "_, tx_test = build_model_data(tX_test,ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 198
    },
    "colab_type": "code",
    "id": "Ya9xiZufEnd2",
    "outputId": "a5f1377a-08a2-4255-b58d-9a733eff30fa"
   },
   "outputs": [],
   "source": [
    "OUTPUT_PATH = 'data/submission.csv' # TODO: fill in desired name of output file for submission\n",
    "y_pred = predict_labels(weights_star, tx_test)\n",
    "create_csv_submission(ids_test, y_pred, OUTPUT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "colab": {
   "collapsed_sections": [],
   "name": "project1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
