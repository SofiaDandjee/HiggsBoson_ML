{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the training data into feature matrix, class labels, and event ids:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from proj1_helpers import *\n",
    "from data_helpers import *\n",
    "from implementations import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_TRAIN_PATH = 'data/train.csv'\n",
    "y, tX, ids = load_csv_data(DATA_TRAIN_PATH)\n",
    "tx, mean, std = standardize(tX,0)\n",
    "y, tx = build_model_data(tx,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(250000, 31)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_samples = len(y)\n",
    "num_features = tx.shape[1]\n",
    "\n",
    "num_samples, num_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Least square gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Descent(0/99): loss=16.692577844567463, weights = [ 0.57122569 -0.09064849  0.0557023   0.3935622  -0.22639175 -0.72902621\n",
      " -0.57393252 -0.32431962  0.62252587 -0.234612   -0.6094945   0.2798321\n",
      "  0.11184731 -0.47426105  0.36164195  0.67326662  0.32952933  0.14684179\n",
      "  0.55277583  0.05160179  0.2935856   0.06113323 -0.18480874 -0.80949152\n",
      " -0.55056252 -0.64252183 -0.59610852 -0.82266379 -0.52111797 -0.15761491\n",
      " -0.86971813]\n",
      "Gradient Descent(1/99): loss=28.153430669735194, weights = [ 0.39404775  0.24705344 -0.38293997  0.1760236   0.81018392  0.6027433\n",
      "  0.72505203  1.00714173 -0.06180126  0.26310081  0.57865957  0.26868254\n",
      "  0.87890468  0.85745457  0.74063176  0.48564494  0.27225451  0.38383443\n",
      "  0.38756799  0.05446717  0.85499382  0.05765083  0.92735512  0.58921301\n",
      "  0.60904473  0.47466402  0.5212432   0.5150888   0.81052653  1.17408312\n",
      "  0.39287109]\n",
      "Gradient Descent(2/99): loss=56.16077822064123, weights = [ 0.2523054  -0.24931398  0.06886477  0.14337908 -0.83535116 -1.3065936\n",
      " -1.11987764 -0.90224601  0.80254012 -0.51820188 -1.26392112  0.10548485\n",
      " -0.26015534 -1.05196091  0.03441404  0.33357013  0.21098263 -0.26218976\n",
      "  0.22891249  0.05777447 -0.15591998  0.02893363 -0.81289706 -1.37408013\n",
      " -0.97471949 -1.03203903 -0.98535122 -1.40427106 -1.09892806 -0.73531843\n",
      " -1.4753566 ]\n",
      "Gradient Descent(3/99): loss=116.84130872077381, weights = [ 0.13891152  0.46270726 -0.68202015 -0.02847437  1.46435265  1.47723082\n",
      "  1.58994952  1.88123334 -0.54300418  0.59396975  1.3602872   0.25168723\n",
      "  1.34655713  1.73185365  0.95729483  0.25844636  0.18419063  0.52087887\n",
      "  0.18670807  0.05249736  1.18103774  0.04405629  1.64593939  1.52694085\n",
      "  1.39988368  1.23938844  1.28617496  1.39436343  1.68483941  2.04846484\n",
      "  1.23517885]\n",
      "Gradient Descent(4/99): loss=245.6939673267863, weights = [ 4.81964170e-02 -5.80444335e-01  3.62254416e-01  7.95417419e-02\n",
      " -1.94273554e+00 -2.56883519e+00 -2.32729886e+00 -2.16470976e+00\n",
      "  1.35122255e+00 -1.02793739e+00 -2.47357085e+00 -8.18898300e-03\n",
      " -1.04722584e+00 -2.31430499e+00 -4.53449842e-01  1.60653708e-01\n",
      "  1.30062565e-01 -6.94573845e-01  6.20772952e-02  5.48115553e-02\n",
      " -8.58094086e-01  1.34904517e-03 -1.96852105e+00 -2.65632383e+00\n",
      " -1.99891527e+00 -2.00449973e+00 -1.95766708e+00 -2.67216149e+00\n",
      " -2.36132918e+00 -1.99766059e+00 -2.69444041e+00]\n",
      "Gradient Descent(5/99): loss=518.2165433643308, weights = [-0.02437567  0.93005595 -1.17872126 -0.17214333  2.96144937  3.30800438\n",
      "  3.38449828  3.71159264 -1.44453433  1.3330528   3.09793354  0.34301552\n",
      "  2.37174237  3.56257113  1.55014621  0.15766099  0.13380865  1.03705839\n",
      "  0.11701629  0.04325928  2.03214057  0.04742609  3.26104443  3.44769129\n",
      "  2.97964172  2.75151749  2.79842429  3.23589648  3.51550008  3.87915304\n",
      "  3.0346853 ]\n",
      "Gradient Descent(6/99): loss=1094.0926889717368, weights = [-0.08243333 -1.26850817  1.04978609  0.12803447 -4.20371477 -5.23936774\n",
      " -4.90033481 -4.83534733  2.58927409 -2.09072341 -4.99055962 -0.18443853\n",
      " -2.6556774  -4.9849476  -1.39405881  0.05981311  0.06791798 -1.49206205\n",
      " -0.04796528  0.05040413 -2.22757806 -0.03179729 -4.35442363 -5.40676865\n",
      " -4.22774215 -4.13122982 -4.08432477 -5.35517828 -5.0320004  -4.66829119\n",
      " -5.2711049 ]\n",
      "Gradient Descent(7/99): loss=2310.738026079544, weights = [-0.12887947  1.92590508 -2.19466114 -0.35561902  6.18057787  7.17757633\n",
      "  7.15785889  7.58062499 -3.29447055  2.89497468  6.78051486  0.56921201\n",
      "  4.59735514  7.43211846  2.86278752  0.12966798  0.11482201  2.18369471\n",
      "  0.13487581  0.02982886  3.91508437  0.07402831  6.70487476  7.47574514\n",
      "  6.26959752  5.89456     5.94154787  7.12702196  7.38499701  7.74864827\n",
      "  6.82364832]\n",
      "Gradient Descent(8/99): loss=4880.987771771412, weights = [-1.66036373e-01 -2.71669246e+00  2.51830882e+00  3.11743211e-01\n",
      " -8.93731461e+00 -1.08762028e+01 -1.03516647e+01 -1.04720826e+01\n",
      "  5.24272170e+00 -4.34188846e+00 -1.03107314e+01 -5.37707561e-01\n",
      " -5.99394361e+00 -1.06219277e+01 -3.34049964e+00 -2.34564440e-02\n",
      "  7.06419600e-03 -3.15272759e+00 -1.68540463e-01  4.95916217e-02\n",
      " -5.05399435e+00 -8.68296470e-02 -9.37605324e+00 -1.12386345e+01\n",
      " -8.97104309e+00 -8.66097240e+00 -8.61404359e+00 -1.10198717e+01\n",
      " -1.06689862e+01 -1.03052340e+01 -1.07325808e+01]\n",
      "Gradient Descent(9/99): loss=10310.74262571088, weights = [-1.95761899e-01  4.03235910e+00 -4.33323451e+00 -6.86087578e-01\n",
      "  1.30148565e+01  1.53579724e+01  1.51141527e+01  1.57601962e+01\n",
      " -7.17580312e+00  6.18570289e+00  1.45491252e+01  1.05997124e+00\n",
      "  9.35551442e+00  1.56125467e+01  5.66355355e+00  1.62000121e-01\n",
      "  1.31551158e-01  4.61284648e+00  2.47957854e-01  1.11447983e-02\n",
      "  7.94711280e+00  1.41682046e-01  1.39913541e+01  1.59692316e+01\n",
      "  1.31936634e+01  1.25073376e+01  1.25543995e+01  1.53513321e+01\n",
      "  1.55653635e+01  1.59289806e+01  1.48071244e+01]\n",
      "Gradient Descent(10/99): loss=21781.267054029893, weights = [ -0.21954232  -5.77529344   5.62421305   0.74162901 -18.90961825\n",
      " -22.77805583 -21.88263377 -22.37341294  10.86705717  -9.10729501\n",
      " -21.56482013  -1.27343014 -12.99404065 -22.52400478  -7.43299554\n",
      "  -0.1345134   -0.07552424  -6.66317986  -0.37295819   0.05794185\n",
      " -10.97957396  -0.19438725 -19.97707372 -23.57053042 -19.01120174\n",
      " -18.25015989 -18.20325469 -22.98223054 -22.57103756 -22.20721617\n",
      " -22.29183233]\n",
      "Gradient Descent(11/99): loss=46013.072448838255, weights = [-2.38566655e-01  8.48170048e+00 -8.84923051e+00 -1.35238163e+00\n",
      "  2.74754737e+01  3.26453131e+01  3.19070879e+01  3.30461047e+01\n",
      " -1.53618986e+01  1.31278398e+01  3.09434900e+01  2.10663080e+00\n",
      "  1.94545078e+01  3.29000369e+01  1.15942578e+01  2.76619932e-01\n",
      "  2.04143745e-01  9.73752034e+00  5.20010984e-01 -1.84055441e-02\n",
      "  1.65033344e+01  2.91167001e-01  2.93895010e+01  3.39029072e+01\n",
      "  2.78056141e+01  2.64619873e+01  2.65091490e+01  3.27298061e+01\n",
      "  3.28527564e+01  3.32162859e+01  3.16506910e+01]\n",
      "Gradient Descent(12/99): loss=97203.42235808377, weights = [ -0.25378612 -12.23808901  12.18655946   1.67495213 -39.95680059\n",
      " -47.91524311 -46.2571729  -47.50918692  22.7579699  -19.18331054\n",
      " -45.35711618  -2.81771899 -27.73947127 -47.66158424 -16.06794614\n",
      "  -0.33574637  -0.21974243 -14.08843675  -0.78331718   0.08502945\n",
      " -23.46453151  -0.41668604 -42.36767325 -49.62889294 -40.23337686\n",
      " -38.51903502 -38.47222345 -48.24882719 -47.70853253 -47.34457581\n",
      " -46.73230646]\n",
      "Gradient Descent(13/99): loss=205344.41902937062, weights = [ -0.2659617   17.8791857  -18.38863183  -2.73934089  58.0407851\n",
      "  69.1707878   67.36746938  69.56886167 -32.64879923  27.78518643\n",
      "  65.55930813   4.32790837  40.82682941  69.42590815  24.13140621\n",
      "   0.54307261   0.38211614  20.55311243   1.10827369  -0.07204554\n",
      "  34.60707554   0.61061612  61.9225586   71.78300369  58.66407344\n",
      "  55.93268733  55.98002597  69.44627482  69.37844991  69.7417872\n",
      "  67.21269234]\n",
      "Gradient Descent(14/99): loss=433795.18520003883, weights = [  -0.27570216  -25.89297921   26.05037196    3.66398063  -84.40485857\n",
      " -101.01302663  -97.76423097 -100.60367858   47.88211814  -40.47635032\n",
      "  -95.63628894   -6.06964391  -58.85584444 -100.76011615  -34.30249072\n",
      "   -0.74291508   -0.50433209  -29.78532133   -1.64202827    0.15028218\n",
      "  -49.81462024   -0.8836028   -89.66428337 -104.68190103  -85.07369034\n",
      "  -81.34454852  -81.29796148 -101.6214511  -100.80685955 -100.44262173\n",
      "  -98.38306402]\n",
      "Gradient Descent(15/99): loss=916403.5704919875, weights = [ -0.28349453  37.72954099 -38.54021191  -5.65435432 122.62370123\n",
      " 146.33674309 142.26329325 146.72937998 -69.16521631  58.74292949\n",
      " 138.66946714   9.03102641  86.00638307 146.59278066  50.62266224\n",
      "   1.11939562   0.77449052  43.39045406   2.35558478  -0.17812003\n",
      "  72.87322608   1.28742504 130.65391249 151.80269706 123.8468441\n",
      " 118.18477912 118.23247022 147.01432038 146.54497241 146.90790065\n",
      " 142.31971183]\n",
      "Gradient Descent(16/99): loss=1935926.753646541, weights = [  -0.28972842  -54.74130386   55.33869867    7.87902392 -178.29121312\n",
      " -213.1788837  -206.58941033 -212.76227927  100.95890527  -85.46394148\n",
      " -201.8683552   -12.92870893 -124.56347989 -212.92747521  -72.81775699\n",
      "   -1.59284329   -1.09210699  -62.95617751   -3.45387165    0.29459362\n",
      " -105.46112964   -1.86856559 -189.57489627 -220.98509929 -179.80558093\n",
      " -171.81908199 -171.77298617 -214.36923637 -212.97376122 -212.60893098\n",
      " -207.51440071]\n",
      "Gradient Descent(17/99): loss=4089696.8717187224, weights = [-2.94715538e-01  7.96620925e+01 -8.11103418e+01 -1.18006468e+01\n",
      "  2.59066926e+02  3.09356284e+02  3.00467686e+02  3.09737735e+02\n",
      " -1.46306779e+02  1.24137259e+02  2.93101442e+02  1.89772362e+01\n",
      "  1.81472895e+02  3.09614338e+02  1.06591563e+02  2.34481772e+00\n",
      "  1.61440571e+00  9.16243922e+01  4.99121219e+00 -3.96484205e-01\n",
      "  1.53727889e+02  2.71819834e+00  2.75855871e+02  3.20844846e+02\n",
      "  2.61542476e+02  2.49690326e+02  2.49738748e+02  3.10882034e+02\n",
      "  3.09565814e+02  3.09927878e+02  3.00968504e+02]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Descent(18/99): loss=8639594.112663293, weights = [-2.98705230e-01 -1.15685844e+02  1.17211655e+02  1.67940281e+01\n",
      " -3.76619677e+02 -4.50128111e+02 -4.36500453e+02 -4.49695880e+02\n",
      "  2.13084603e+02 -1.80505523e+02 -4.26300887e+02 -2.74079460e+01\n",
      " -2.63351846e+02 -4.49879798e+02 -1.54177047e+02 -3.38208430e+00\n",
      " -2.32474792e+00 -1.33040821e+02 -7.28178612e+00  6.04485358e-01\n",
      " -2.23001532e+02 -3.94863941e+00 -4.00633247e+02 -4.66679813e+02\n",
      " -3.79933335e+02 -3.62952003e+02 -3.62906956e+02 -4.52548993e+02\n",
      " -4.49925094e+02 -4.49559012e+02 -4.38073201e+02]\n",
      "Gradient Descent(19/99): loss=18251374.276022263, weights = [-3.01896984e-01  1.68244246e+02 -1.71040369e+02 -2.47751830e+01\n",
      "  5.47314943e+02  6.53743395e+02  6.34663935e+02  6.54101509e+02\n",
      " -3.09271473e+02  2.62281012e+02  6.19329441e+02  3.99995262e+01\n",
      "  3.83166837e+02  6.54005785e+02  2.24832517e+02  4.93858553e+00\n",
      "  3.39619684e+00  1.93509813e+02  1.05580837e+01 -8.53386546e-01\n",
      "  3.24548107e+02  5.74120266e+00  5.82604765e+02  6.77950273e+02\n",
      "  5.52424614e+02  5.27496783e+02  5.27546741e+02  6.57059803e+02\n",
      "  6.53955773e+02  6.54316012e+02  6.36103263e+02]\n",
      "Gradient Descent(20/99): loss=38556518.10808072, weights = [-3.04450387e-01 -2.44434121e+02  2.47920377e+02  3.56360946e+01\n",
      " -7.95586666e+02 -9.50685962e+02 -9.22208322e+02 -9.50220429e+02\n",
      "  4.49951579e+02 -3.81286459e+02 -9.00433625e+02 -5.79851673e+01\n",
      " -5.56529763e+02 -9.50444111e+02 -3.26045645e+02 -7.15778416e+00\n",
      " -4.92259587e+00 -2.81106338e+02 -1.53696801e+01  1.26296742e+00\n",
      " -4.71297756e+02 -8.34256191e+00 -8.46493512e+02 -9.85716799e+02\n",
      " -8.02711764e+02 -7.66727585e+02 -7.66684761e+02 -9.55707442e+02\n",
      " -9.50487294e+02 -9.50118565e+02 -9.25149142e+02]\n",
      "Gradient Descent(21/99): loss=81451679.98390141, weights = [-3.06493110e-01  3.55375311e+02 -3.61019611e+02 -5.21760355e+01\n",
      "  1.15625313e+03  1.38127400e+03  1.34064806e+03  1.38158310e+03\n",
      " -6.53540742e+02  5.54110769e+02  1.30848254e+03  8.44201141e+01\n",
      "  8.09265056e+02  1.38154563e+03  4.74624755e+02  1.04214213e+01\n",
      "  7.16534623e+00  4.08735912e+02  2.23167387e+01 -1.81528688e+00\n",
      "  6.85420105e+02  1.21275483e+01  1.23062650e+03  1.43234508e+03\n",
      "  1.16691811e+03  1.11436855e+03  1.11442174e+03  1.38837220e+03\n",
      "  1.38149249e+03  1.38184888e+03  1.34407091e+03]\n",
      "Gradient Descent(22/99): loss=172068861.89294508, weights = [-3.08127288e-01 -5.16419252e+02  5.24046332e+02  7.54480835e+01\n",
      " -1.68065981e+03 -2.00812445e+03 -1.94829348e+03 -2.00758828e+03\n",
      "  9.50337134e+02 -8.05443868e+02 -1.90206345e+03 -1.22570068e+02\n",
      " -1.17586331e+03 -2.00789618e+03 -6.89117669e+02 -1.51311491e+01\n",
      " -1.04064306e+01 -5.93908091e+02 -3.24571609e+01  2.65689574e+00\n",
      " -9.95821666e+02 -1.76247600e+01 -1.78837861e+03 -2.08219613e+03\n",
      " -1.69584510e+03 -1.61971594e+03 -1.61967781e+03 -2.01864073e+03\n",
      " -2.00793487e+03 -2.00756055e+03 -1.95412298e+03]\n",
      "Gradient Descent(23/99): loss=363500093.248261, weights = [-3.09434630e-01  7.50693935e+02 -7.62355685e+02 -1.10053969e+02\n",
      "  2.44265673e+03  2.91820523e+03  2.83204445e+03  2.91841107e+03\n",
      " -1.38082137e+03  1.17060697e+03  2.76432590e+03  1.78269956e+02\n",
      "  1.70942019e+03  2.91849643e+03  1.00232253e+03  2.20065472e+01\n",
      "  1.51312420e+01  8.63397665e+02  4.71556214e+01 -3.84485627e+00\n",
      "  1.44777942e+03  2.56188959e+01  2.59959670e+03  3.02602481e+03\n",
      "  2.46504983e+03  2.35414954e+03  2.35420958e+03  2.93329165e+03\n",
      "  2.91843673e+03  2.91878498e+03  2.83965944e+03]\n",
      "Gradient Descent(24/99): loss=767903712.584768, weights = [-3.10480504e-01 -1.09099579e+03  1.10736992e+03  1.59558630e+02\n",
      " -3.55039576e+03 -4.24198852e+03 -4.11593977e+03 -4.24130286e+03\n",
      "  2.00741232e+03 -1.70148954e+03 -4.01804391e+03 -2.58997402e+02\n",
      " -2.48421218e+03 -4.24178887e+03 -1.45611216e+03 -3.19729391e+01\n",
      " -2.19883074e+01 -1.25471916e+03 -6.85564734e+01  5.60373119e+00\n",
      " -2.10388587e+03 -3.72336728e+01 -3.77812913e+03 -4.39853756e+03\n",
      " -3.58261539e+03 -3.42167795e+03 -3.42164976e+03 -4.26411361e+03\n",
      " -4.24181806e+03 -4.24143191e+03 -4.12786939e+03]\n",
      "Gradient Descent(25/99): loss=1622217223.365524, weights = [-3.11317203e-01  1.58581464e+03 -1.61018891e+03 -2.32316412e+02\n",
      "  5.16022331e+03  6.16501674e+03  5.98264580e+03  6.16500472e+03\n",
      " -2.91722412e+03  2.47297022e+03  5.83982407e+03  3.76540117e+02\n",
      "  3.61103083e+03  6.16534938e+03  2.11710312e+03  4.64823264e+01\n",
      "  3.19617915e+01  1.82387405e+03  9.96269471e+01 -8.13055313e+00\n",
      "  3.05828984e+03  5.41196838e+01  5.49159022e+03  6.39271685e+03\n",
      "  5.20738601e+03  4.97321914e+03  4.97329361e+03  6.19697764e+03\n",
      "  6.16527582e+03  6.16560688e+03  5.99911941e+03]\n",
      "Gradient Descent(26/99): loss=3426977467.3502784, weights = [-3.11986563e-01 -2.30480454e+03  2.33965661e+03  3.37250305e+02\n",
      " -7.50025915e+03 -8.96108352e+03 -8.69516417e+03 -8.96008177e+03\n",
      "  4.24050906e+03 -3.59441149e+03 -8.48811902e+03 -5.47194116e+02\n",
      " -5.24812661e+03 -8.96094423e+03 -3.07640383e+03 -6.75500054e+01\n",
      " -4.64533580e+01 -2.65070892e+03 -1.44818638e+02  1.18305621e+01\n",
      " -4.44469605e+03 -7.86580903e+01 -7.98152328e+03 -9.29187016e+03\n",
      " -7.56847011e+03 -7.22837207e+03 -7.22836486e+03 -9.00773332e+03\n",
      " -8.96095333e+03 -8.96054221e+03 -8.71997751e+03]\n",
      "Gradient Descent(27/99): loss=7239581970.456288, weights = [-3.12522050e-01  3.35002929e+03 -3.40125953e+03 -4.90593543e+02\n",
      "  1.09011594e+04  1.30239961e+04  1.26383626e+04  1.30235241e+04\n",
      " -6.16291930e+03  5.22424632e+03  1.23368875e+04  7.95400696e+02\n",
      "  7.62824120e+03  1.30244163e+04  4.47211180e+03  9.81895483e+01\n",
      "  6.75184192e+01  3.85289777e+03  2.10472727e+02 -1.71828665e+01\n",
      "  6.46054101e+03  1.14328293e+02  1.16010116e+04  1.35049452e+04\n",
      "  1.10006432e+04  1.05060732e+04  1.05061782e+04  1.30916040e+04\n",
      "  1.30243135e+04  1.30246083e+04  1.26735536e+04]\n",
      "Gradient Descent(28/99): loss=15293811414.81132, weights = [-3.12950440e-01 -4.86900835e+03  4.94289514e+03  7.12634015e+02\n",
      " -1.58444483e+04 -1.89302958e+04 -1.83689117e+04 -1.89286261e+04\n",
      "  8.95798276e+03 -7.59326111e+03 -1.79312814e+04 -1.15600804e+03\n",
      " -1.10869641e+04 -1.89302840e+04 -6.49930888e+03 -1.42706192e+02\n",
      " -9.81350730e+01 -5.59978309e+03 -3.05925722e+02  2.49860519e+01\n",
      " -9.38971632e+03 -1.66168359e+02 -1.68612990e+04 -1.96291657e+04\n",
      " -1.59886968e+04 -1.52701164e+04 -1.52701535e+04 -1.90287555e+04\n",
      " -1.89302506e+04 -1.89297867e+04 -1.84209387e+04]\n",
      "Gradient Descent(29/99): loss=32308587505.39788, weights = [-3.13293152e-01  7.07698000e+03 -7.18494460e+03 -1.03620591e+03\n",
      "  2.30290443e+04  2.75137767e+04  2.66987305e+04  2.75123333e+04\n",
      " -1.30195407e+04  1.10363899e+04  2.60621003e+04  1.68026414e+03\n",
      "  1.61147113e+04  2.75143821e+04  9.44713545e+03  2.07423629e+02\n",
      "  1.42633881e+02  8.13925674e+03  4.44636294e+02 -3.63051463e+01\n",
      "  1.36478917e+04  2.41520524e+02  2.45073358e+04  2.85297199e+04\n",
      "  2.32390532e+04  2.21943753e+04  2.21945447e+04  2.76566892e+04\n",
      "  2.75142175e+04  2.75144356e+04  2.67734661e+04]\n",
      "Gradient Descent(30/99): loss=68252759125.155594, weights = [-3.13567322e-01 -1.02859578e+04  1.04423062e+04  1.50564696e+03\n",
      " -3.34717692e+04 -3.99905221e+04 -3.88049757e+04 -3.99874410e+04\n",
      "  1.89237695e+04 -1.60409393e+04 -3.78802237e+04 -2.44213475e+03\n",
      " -2.34216604e+04 -3.99907795e+04 -1.37302833e+04 -3.01474590e+02\n",
      " -2.07313145e+02 -1.18297895e+04 -6.46269798e+02  5.27782103e+01\n",
      " -1.98362012e+04 -3.51036224e+02 -3.56200562e+04 -4.14669789e+04\n",
      " -3.37766533e+04 -3.22585181e+04 -3.22586488e+04 -4.01984322e+04\n",
      " -3.99906564e+04 -3.99900811e+04 -3.89144885e+04]\n",
      "Gradient Descent(31/99): loss=144185787367.89908, weights = [-3.13786657e-01  1.49502635e+04 -1.51780813e+04 -2.18882215e+03\n",
      "  4.86495296e+04  5.81238301e+04  5.64016233e+04  5.81203347e+04\n",
      " -2.75043409e+04  2.33146986e+04  5.50569735e+04  3.54957085e+03\n",
      "  3.40426117e+04  5.81248267e+04  1.99570110e+04  4.38184519e+02\n",
      "  3.01318093e+02  1.71942974e+04  9.39312172e+02 -7.67007655e+01\n",
      "  2.88313661e+04  5.10217464e+02  5.17722999e+04  6.02699614e+04\n",
      "  4.90930220e+04  4.68862269e+04  4.68865325e+04  5.84258249e+04\n",
      "  5.81245316e+04  5.81245876e+04  5.65599019e+04]\n",
      "Gradient Descent(32/99): loss=304596349589.4615, weights = [-3.13962126e-01 -2.17294091e+04  2.20599593e+04  3.18091247e+03\n",
      " -7.07099557e+04 -8.44808137e+04 -8.19767219e+04 -8.44747506e+04\n",
      "  3.99767587e+04 -3.38868874e+04 -8.00229074e+04 -5.15910323e+03\n",
      " -4.94790342e+04 -8.44816398e+04 -2.90059067e+04 -6.36876228e+02\n",
      " -4.37954110e+02 -2.49908531e+04 -1.36525667e+03  1.11490498e+02\n",
      " -4.19046785e+04 -7.41574617e+02 -7.52484275e+04 -8.75999447e+04\n",
      " -7.13541905e+04 -6.81469735e+04 -6.81473021e+04 -8.49199413e+04\n",
      " -8.44813271e+04 -8.44805163e+04 -8.22076707e+04]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Descent(33/99): loss=643467971961.445, weights = [-3.14102501e-01  3.15827866e+04 -3.20637979e+04 -4.62375073e+03\n",
      "  1.02773495e+05  1.22788392e+05  1.19149770e+05  1.22780562e+05\n",
      " -5.81038735e+04  4.92529547e+04  1.16309415e+05  7.49854008e+03\n",
      "  7.19157860e+04  1.22790215e+05  4.21594095e+04  9.25673883e+02\n",
      "  6.36543289e+02  3.63233064e+04  1.98432746e+03 -1.62037079e+02\n",
      "  6.09068660e+04  1.07784691e+03  1.09370276e+05  1.27322076e+05\n",
      "  1.03710224e+05  9.90484264e+04  9.90490195e+04  1.23426452e+05\n",
      "  1.22789645e+05  1.22789359e+05  1.19484540e+05]\n",
      "Gradient Descent(34/99): loss=1359343378534.8296, weights = [-3.14214800e-01 -4.59040072e+04  4.66025631e+04  6.71995987e+03\n",
      " -1.49376623e+05 -1.78467748e+05 -1.73178207e+05 -1.78455385e+05\n",
      "  8.44517608e+04 -7.15869329e+04 -1.69050466e+05 -1.08987637e+04\n",
      " -1.04525934e+05 -1.78469775e+05 -6.12760674e+04 -1.34542049e+03\n",
      " -9.25188900e+02 -5.27939611e+04 -2.88413649e+03  2.35522224e+02\n",
      " -8.85249276e+04 -1.56659751e+03 -1.58964419e+05 -1.85057073e+05\n",
      " -1.50737749e+05 -1.43962300e+05 -1.43963047e+05 -1.79395329e+05\n",
      " -1.78469062e+05 -1.78467754e+05 -1.73665688e+05]\n",
      "Gradient Descent(35/99): loss=2871649408025.9707, weights = [-3.14304641e-01  6.67194386e+04 -6.77353282e+04 -9.76759894e+03\n",
      "  2.17111829e+05  2.59394020e+05  2.51706906e+05  2.59377033e+05\n",
      " -1.22746211e+05  1.04048217e+05  2.45706837e+05  1.58408520e+04\n",
      "  1.51923887e+05  2.59397589e+05  8.90625771e+04  1.95550890e+03\n",
      "  1.34471589e+03  7.67338444e+04  4.19194966e+03 -3.42311957e+02\n",
      "  1.28667223e+05  2.27697933e+03  2.31047556e+05  2.68971470e+05\n",
      "  2.19090531e+05  2.09242474e+05  2.09243674e+05  2.60742026e+05\n",
      "  2.59396436e+05  2.59395426e+05  2.52414523e+05]\n",
      "Gradient Descent(36/99): loss=6066436525776.645, weights = [-3.14376511e-01 -9.69734950e+04  9.84494724e+04  1.41962963e+04\n",
      " -3.15562070e+05 -3.77017669e+05 -3.65843807e+05 -3.76991998e+05\n",
      "  1.78406395e+05 -1.51229293e+05 -3.57123580e+05 -2.30239425e+04\n",
      " -2.20813985e+05 -3.77022235e+05 -1.29447645e+05 -2.84223870e+03\n",
      " -1.95448518e+03 -1.11528781e+05 -6.09281151e+03  4.97542899e+02\n",
      " -1.87011454e+05 -3.30948058e+03 -3.35816694e+05 -3.90937874e+05\n",
      " -3.18437649e+05 -3.04124215e+05 -3.04125845e+05 -3.78977123e+05\n",
      " -3.77020675e+05 -3.77018316e+05 -3.66873215e+05]\n",
      "Gradient Descent(37/99): loss=12815510144944.107, weights = [-3.14434011e-01  1.40946560e+05 -1.43092395e+05 -2.06341129e+04\n",
      "  4.58654633e+05  5.47977080e+05  5.31737404e+05  5.47940750e+05\n",
      " -2.59304890e+05  2.19804679e+05  5.19062362e+05  3.34642180e+04\n",
      "  3.20943151e+05  5.47984337e+05  1.88146782e+05  4.13106358e+03\n",
      "  2.84074978e+03  1.62102185e+05  8.85561032e+03 -7.23147206e+02\n",
      "  2.71812801e+05  4.81017874e+03  4.88094086e+05  5.68209622e+05\n",
      "  4.62834527e+05  4.42030359e+05  4.42032843e+05  5.50824865e+05\n",
      "  5.47981954e+05  5.47979417e+05  5.33232676e+05]\n",
      "Gradient Descent(38/99): loss=27073109489782.246, weights = [-3.14480006e-01 -2.04859160e+05  2.07977461e+05  2.99902613e+04\n",
      " -6.66633289e+05 -7.96459711e+05 -7.72855072e+05 -7.96405925e+05\n",
      "  3.76888080e+05 -3.19475918e+05 -7.54433094e+05 -4.86387005e+04\n",
      " -4.66475617e+05 -7.96469637e+05 -2.73461931e+05 -6.00430690e+03\n",
      " -4.12890103e+03 -2.35607673e+05 -1.28712242e+04  1.05106885e+03\n",
      " -3.95066887e+05 -6.99136792e+03 -7.09421868e+05 -8.25866595e+05\n",
      " -6.72708194e+05 -6.42470564e+05 -6.42474059e+05 -8.00599023e+05\n",
      " -7.96466289e+05 -7.96461710e+05 -7.75029311e+05]\n",
      "Gradient Descent(39/99): loss=57192671158308.195, weights = [-3.14516809e-01  2.97753349e+05 -3.02286224e+05 -4.35899122e+04\n",
      "  9.68920297e+05  1.15761655e+06  1.12330935e+06  1.15753936e+06\n",
      " -5.47788770e+05  4.64343315e+05  1.09653325e+06  7.06940599e+04\n",
      "  6.78000889e+05  1.15763160e+06  3.97464832e+05  8.72698173e+03\n",
      "  6.00116174e+03  3.42445090e+05  1.87077183e+04 -1.52767170e+03\n",
      "  5.74211679e+05  1.01616305e+04  1.03111179e+06  1.20035826e+06\n",
      "  9.77750268e+05  9.33801021e+05  9.33806215e+05  1.16363266e+06\n",
      "  1.15762662e+06  1.15762085e+06  1.12646856e+06]\n",
      "Gradient Descent(40/99): loss=120821054391881.97, weights = [-3.14546241e-01 -4.32770525e+05  4.39358279e+05  6.33554400e+04\n",
      " -1.40828067e+06 -1.68254229e+06 -1.63267732e+06 -1.68242911e+06\n",
      "  7.96185970e+05 -6.74901436e+05 -1.59376012e+06 -1.02750558e+05\n",
      " -9.85442413e+05 -1.68256354e+06 -5.77695974e+05 -1.26842605e+04\n",
      " -8.72241278e+03 -4.97727673e+05 -2.71908036e+04  2.22040747e+03\n",
      " -8.34589576e+05 -1.47694539e+04 -1.49867283e+06 -1.74466520e+06\n",
      " -1.42111424e+06 -1.35723632e+06 -1.35724375e+06 -1.69128661e+06\n",
      " -1.68255642e+06 -1.68254715e+06 -1.63727003e+06]\n",
      "Gradient Descent(41/99): loss=255237723448170.75, weights = [-3.14569802e-01  6.29011903e+05 -6.38587465e+05 -9.20846519e+04\n",
      "  2.04687022e+06  2.44549631e+06  2.37302095e+06  2.44533279e+06\n",
      " -1.15721872e+06  9.80937754e+05  2.31645600e+06  1.49343109e+05\n",
      "  1.43229496e+06  2.44552782e+06  8.39654839e+05  1.84359826e+04\n",
      "  1.26776170e+04  7.23424316e+05  3.95205607e+04 -3.22725115e+03\n",
      "  1.21303744e+06  2.14667162e+04  2.17825130e+06  2.53578924e+06\n",
      "  2.06552360e+06  1.97267975e+06  1.97269068e+06  2.45820558e+06\n",
      "  2.44551735e+06  2.44550477e+06  2.37969531e+06]\n",
      "Gradient Descent(42/99): loss=539196548142213.5, weights = [-3.14588628e-01 -9.14239407e+05  9.28156472e+05  1.33840279e+05\n",
      " -2.97503069e+06 -3.55441554e+06 -3.44907492e+06 -3.55417690e+06\n",
      "  1.68196402e+06 -1.42574739e+06 -3.36686102e+06 -2.17063302e+05\n",
      " -2.08177371e+06 -3.55446072e+06 -1.22039856e+06 -2.67958417e+04\n",
      " -1.84263297e+04 -1.05146322e+06 -5.74413001e+04  4.69066686e+03\n",
      " -1.76309306e+06 -3.12008694e+04 -3.16598669e+06 -3.68565194e+06\n",
      " -3.00214212e+06 -2.86719817e+06 -2.86721393e+06 -3.57288807e+06\n",
      " -3.55444562e+06 -3.55442644e+06 -3.45877673e+06]\n",
      "Gradient Descent(43/99): loss=1139067194303313.8, weights = [-3.14603721e-01  1.32880450e+06 -1.34903287e+06 -1.94531089e+05\n",
      "  4.32406840e+06  5.16617690e+06  5.01307029e+06  5.16583102e+06\n",
      " -2.44465586e+06  2.07225738e+06  4.89357559e+06  3.15491344e+05\n",
      "  3.02576144e+06  5.16624319e+06  1.77379311e+06  3.89465082e+04\n",
      "  2.67818082e+04  1.52825316e+06  8.34882491e+04 -6.81765829e+03\n",
      "  2.56257401e+06  4.53490135e+04  4.60161432e+06  5.35692307e+06\n",
      "  4.36347399e+06  4.16733899e+06  4.16736201e+06  5.19302568e+06\n",
      "  5.16622112e+06  5.16619414e+06  5.02717048e+06]\n",
      "Gradient Descent(44/99): loss=2406310050775407.0, weights = [-3.14615750e-01 -1.93135535e+06  1.96075579e+06  2.82741399e+05\n",
      " -6.28483219e+06 -7.50879808e+06 -7.28626366e+06 -7.50829438e+06\n",
      "  3.55319396e+06 -3.01192965e+06 -7.11258431e+06 -4.58552039e+05\n",
      " -4.39780303e+06 -7.50889380e+06 -2.57812504e+06 -5.66069359e+04\n",
      " -3.89261148e+04 -2.22124445e+06 -1.21346287e+05  9.90915627e+03\n",
      " -3.72458163e+06 -6.59126761e+04 -6.68823199e+06 -7.78603858e+06\n",
      " -6.34210599e+06 -6.05703316e+06 -6.05706651e+06 -7.54782171e+06\n",
      " -7.50886184e+06 -7.50882174e+06 -7.30675858e+06]\n",
      "Gradient Descent(45/99): loss=5083394631520613.0, weights = [-3.14625440e-01  2.80713516e+06 -2.84986788e+06 -4.10951938e+05\n",
      "  9.13471074e+06  1.09136878e+07  1.05902454e+07  1.09129566e+07\n",
      " -5.16440142e+06  4.37769942e+06  1.03378100e+07  6.66483962e+05\n",
      "  6.39200219e+06  1.09138275e+07  3.74718531e+06  8.22755448e+04\n",
      "  5.65772912e+04  3.22847571e+06  1.76371172e+05 -1.44024897e+04\n",
      "  5.41350629e+06  9.58010080e+04  9.72103382e+06  1.13166441e+07\n",
      "  9.21795594e+06  8.80361559e+06  8.80366417e+06  1.09704066e+07\n",
      "  1.09137809e+07  1.09137235e+07  1.06200329e+07]\n",
      "Gradient Descent(46/99): loss=1.0738807732381078e+16, weights = [-3.14633095e-01 -4.08004012e+06  4.14214958e+06  5.97299018e+05\n",
      " -1.32768768e+07 -1.58625374e+07 -1.53924280e+07 -1.58614738e+07\n",
      "  7.50621747e+06 -6.36278227e+06 -1.50255254e+07 -9.68703477e+05\n",
      " -9.29047719e+06 -1.58627399e+07 -5.44635871e+06 -1.19583673e+05\n",
      " -8.22324616e+04 -4.69243873e+06 -2.56347289e+05  2.09333554e+04\n",
      " -7.86827892e+06 -1.39242301e+05 -1.41290698e+07 -1.64482155e+07\n",
      " -1.33978694e+07 -1.27956453e+07 -1.27957158e+07 -1.59449758e+07\n",
      " -1.58626724e+07 -1.58625880e+07 -1.54357236e+07]\n",
      "Gradient Descent(47/99): loss=2.268601984940663e+16, weights = [-3.14639359e-01  5.93014840e+06 -6.02042217e+06 -8.68146793e+05\n",
      "  1.92973219e+07  2.30554588e+07  2.23721778e+07  2.30539139e+07\n",
      " -1.09099370e+07  9.24800766e+06  2.18389013e+07  1.40796530e+06\n",
      "  1.35032762e+07  2.30557538e+07  7.91602936e+06  1.73809299e+05\n",
      "  1.19521049e+05  6.82024152e+06  3.72588841e+05 -3.04256499e+04\n",
      "  1.14361773e+07  2.02382202e+05  2.05359451e+07  2.39067148e+07\n",
      "  1.94731795e+07  1.85978745e+07  1.85979770e+07  2.31752790e+07\n",
      "  2.30556554e+07  2.30555338e+07  2.24351050e+07]\n",
      "Gradient Descent(48/99): loss=4.792482642703741e+16, weights = [-3.14644167e-01 -8.61919441e+06  8.75040257e+06  1.26181044e+06\n",
      " -2.80477588e+07 -3.35100362e+07 -3.25169179e+07 -3.35077897e+07\n",
      "  1.58570858e+07 -1.34415485e+07 -3.17418261e+07 -2.04641209e+06\n",
      " -1.96263828e+07 -3.35104643e+07 -1.15055794e+07 -2.52623722e+05\n",
      " -1.73718283e+05 -9.91290305e+06 -5.41540533e+05  4.42222724e+04\n",
      " -1.66219508e+07 -2.94153102e+05 -2.98480397e+07 -3.47472970e+07\n",
      " -2.83033592e+07 -2.70311444e+07 -2.70312934e+07 -3.36841895e+07\n",
      " -3.35103215e+07 -3.35101438e+07 -3.26083806e+07]\n",
      "Gradient Descent(49/99): loss=1.012424834020285e+17, weights = [-3.14648314e-01  1.25275978e+07 -1.27183033e+07 -1.83398320e+06\n",
      "  4.07661111e+07  4.87052765e+07  4.72618264e+07  4.87020122e+07\n",
      " -2.30475352e+07  1.95366647e+07  4.61352658e+07  2.97436457e+06\n",
      "  2.85260337e+07  4.87058993e+07  1.67228244e+07  3.67176814e+05\n",
      "  2.52491430e+05  1.44079433e+07  7.87103939e+05 -6.42750062e+04\n",
      "  2.41592317e+07  4.27537837e+05  4.33827356e+07  5.05035776e+07\n",
      "  4.11376147e+07  3.92885095e+07  3.92887261e+07  4.89583999e+07\n",
      "  4.87056916e+07  4.87054342e+07  4.73947622e+07]\n",
      "Gradient Descent(50/99): loss=2.1387746622337376e+17, weights = [-3.14651194e-01 -1.82082798e+07  1.84854608e+07  2.66560868e+06\n",
      " -5.92516440e+07 -7.07908516e+07 -6.86928629e+07 -7.07861062e+07\n",
      "  3.34985196e+07 -2.83956323e+07 -6.70554603e+07 -4.32310048e+06\n",
      " -4.14612611e+07 -7.07917562e+07 -2.43058458e+07 -5.33674399e+05\n",
      " -3.66984538e+05 -2.09412742e+07 -1.14401892e+06  9.34207353e+04\n",
      " -3.51143177e+07 -6.21406332e+05 -6.30547857e+07 -7.34045983e+07\n",
      " -5.97916068e+07 -5.71040188e+07 -5.71043335e+07 -7.11587549e+07\n",
      " -7.07914544e+07 -7.07910794e+07 -6.88860800e+07]\n",
      "Gradient Descent(51/99): loss=4.5182189354725965e+17, weights = [-3.14654130e-01  2.64648868e+07 -2.68677571e+07 -3.87433857e+06\n",
      "  8.61195050e+07  1.02891205e+08  9.98418777e+07  1.02884309e+08\n",
      " -4.86885376e+07  4.12717290e+07  9.74619885e+07  6.28342510e+06\n",
      "  6.02620124e+07  1.02892521e+08  3.53274156e+07  7.75670884e+05\n",
      "  5.33394931e+05  3.04371671e+07  1.66277822e+06 -1.35782681e+05\n",
      "  5.10370258e+07  9.03185167e+05  9.16471945e+07  1.06690165e+08\n",
      "  8.69043161e+07  8.29980319e+07  8.29984894e+07  1.03425935e+08\n",
      "  1.02892082e+08  1.02891538e+08  1.00122709e+08]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Descent(52/99): loss=9.544858890156316e+17, weights = [-3.14655565e-01 -3.84654803e+07  3.90510330e+07  5.63117017e+06\n",
      " -1.25170690e+08 -1.49547576e+08 -1.45115519e+08 -1.49537551e+08\n",
      "  7.07665224e+07 -5.99865360e+07 -1.41656461e+08 -9.13266587e+06\n",
      " -8.75880282e+07 -1.49549487e+08 -5.13467526e+07 -1.12740151e+06\n",
      " -7.75264694e+05 -4.42390045e+07 -2.41677071e+06  1.97353810e+05\n",
      " -7.41799398e+07 -1.31273757e+06 -1.33204929e+08 -1.55069186e+08\n",
      " -1.26311376e+08 -1.20633774e+08 -1.20634439e+08 -1.50324781e+08\n",
      " -1.49548849e+08 -1.49548058e+08 -1.45523695e+08]\n",
      "Gradient Descent(53/99): loss=2.016377084291707e+18, weights = [-3.14658031e-01  5.59077844e+07 -5.67588584e+07 -8.18464409e+06\n",
      "  1.81929768e+08  2.17360436e+08  2.10918649e+08  2.17345867e+08\n",
      " -1.02855844e+08  8.71876364e+07  2.05891069e+08  1.32739044e+07\n",
      "  1.27305120e+08  2.17363214e+08  7.46301142e+07  1.63862558e+06\n",
      "  1.12681112e+06  6.42993331e+07  3.51266367e+06 -2.86844564e+05\n",
      "  1.07817088e+08  1.90800293e+06  1.93607161e+08  2.25385839e+08\n",
      "  1.83587703e+08  1.75335572e+08  1.75336539e+08  2.18490068e+08\n",
      "  2.17362288e+08  2.17361138e+08  2.11511912e+08]\n",
      "Gradient Descent(54/99): loss=4.259650763668953e+18, weights = [-3.14658092e-01 -8.12593607e+07  8.24963566e+07  1.18959985e+07\n",
      " -2.64426445e+08 -3.15923271e+08 -3.06560432e+08 -3.15902095e+08\n",
      "  1.49496180e+08 -1.26723169e+08 -2.99253080e+08 -1.92930020e+07\n",
      " -1.85032063e+08 -3.15927309e+08 -1.08471395e+08 -2.38166597e+06\n",
      " -1.63776749e+06 -9.34560857e+07 -5.10549305e+06  4.16915222e+05\n",
      " -1.56707116e+08 -2.77319339e+06 -2.81398991e+08 -3.27587821e+08\n",
      " -2.66836175e+08 -2.54842088e+08 -2.54843493e+08 -3.17565138e+08\n",
      " -3.15925962e+08 -3.15924290e+08 -3.07422714e+08]\n",
      "Gradient Descent(55/99): loss=8.998626680385524e+18, weights = [-3.14660928e-01  1.18106696e+08 -1.19904613e+08 -1.72902803e+07\n",
      "  3.84331523e+08  4.59179761e+08  4.45571312e+08  4.59148983e+08\n",
      " -2.17285734e+08  1.84186224e+08  4.34950415e+08  2.80414797e+07\n",
      "  2.68935486e+08  4.59185630e+08  1.57658121e+08  3.46164057e+06\n",
      "  2.38041877e+06  1.35834069e+08  7.42059637e+06 -6.05966852e+05\n",
      "  2.27766495e+08  4.03070745e+06  4.09000328e+08  4.76133641e+08\n",
      "  3.87833954e+08  3.70401107e+08  3.70403149e+08  4.61566138e+08\n",
      "  4.59183673e+08  4.59181243e+08  4.46824598e+08]\n",
      "Gradient Descent(56/99): loss=1.900984062439911e+19, weights = [-3.14659140e-01 -1.71662583e+08  1.74275770e+08  2.51306167e+07\n",
      " -5.58607970e+08 -6.67396398e+08 -6.47617150e+08 -6.67351663e+08\n",
      "  3.15814696e+08 -2.67706099e+08 -6.32180172e+08 -4.07569849e+07\n",
      " -3.90885204e+08 -6.67404928e+08 -2.29148736e+08 -5.03133335e+06\n",
      " -3.45982783e+06 -1.97428492e+08 -1.07854912e+07  8.80744605e+05\n",
      " -3.31047993e+08 -5.85844555e+06 -5.94462929e+08 -6.92038073e+08\n",
      " -5.63698589e+08 -5.38360758e+08 -5.38363726e+08 -6.70864886e+08\n",
      " -6.67402083e+08 -6.67398550e+08 -6.49438743e+08]\n",
      "Gradient Descent(57/99): loss=4.015879904794192e+19, weights = [-3.14663614e-01  2.49503569e+08 -2.53301716e+08 -3.65261815e+07\n",
      "  8.11910668e+08  9.70029582e+08  9.41281367e+08  9.69964562e+08\n",
      " -4.59021951e+08  3.89098347e+08  9.18844438e+08  5.92383793e+07\n",
      "  5.68133440e+08  9.70041980e+08  3.33057016e+08  7.31280870e+06\n",
      "  5.02869861e+06  2.86953119e+08  1.56762092e+07 -1.28012126e+06\n",
      "  4.81162840e+08  8.51497777e+06  8.64024182e+08  1.00584511e+09\n",
      "  8.19309647e+08  7.82482290e+08  7.82486603e+08  9.75070868e+08\n",
      "  9.70037845e+08  9.70032712e+08  9.43928967e+08]\n",
      "Gradient Descent(58/99): loss=8.483654191729872e+19, weights = [-3.14658600e-01 -3.62641818e+08  3.68162247e+08  5.30891031e+07\n",
      " -1.18007434e+09 -1.40989282e+09 -1.36810863e+09 -1.40979832e+09\n",
      "  6.67167029e+08 -5.65536326e+08 -1.33549760e+09 -8.61002256e+07\n",
      " -8.25755495e+08 -1.40991084e+09 -4.84082861e+08 -1.06288269e+07\n",
      " -7.30897924e+06 -4.17072994e+08 -2.27846400e+07  1.86059664e+06\n",
      " -6.99347779e+08 -1.23761236e+07 -1.25581891e+09 -1.46194902e+09\n",
      " -1.19082841e+09 -1.13730157e+09 -1.13730784e+09 -1.41722010e+09\n",
      " -1.40990483e+09 -1.40989737e+09 -1.37195679e+09]\n",
      "Gradient Descent(59/99): loss=1.7921947406578156e+20, weights = [-3.14666998e-01  5.27082993e+08 -5.35106680e+08 -7.71625394e+07\n",
      "  1.71518310e+09  2.04921355e+09  1.98848218e+09  2.04907620e+09\n",
      " -9.69696205e+08  8.21980712e+08  1.94108356e+09  1.25142668e+08\n",
      "  1.20019716e+09  2.04923974e+09  7.03591895e+08  1.54485049e+07\n",
      "  1.06232609e+07  6.06196173e+08  3.31164131e+07 -2.70429055e+06\n",
      "  1.01646943e+09  1.79881193e+07  1.82527430e+09  2.12487482e+09\n",
      "  1.73081364e+09  1.65301486e+09  1.65302397e+09  2.05986341e+09\n",
      "  2.04923101e+09  2.04922016e+09  1.99407530e+09]\n",
      "Gradient Descent(60/99): loss=3.786059539735453e+20, weights = [-3.14655658e-01 -7.66090583e+08  7.77752637e+08  1.12152157e+08\n",
      " -2.49293876e+09 -2.97843646e+09 -2.89016623e+09 -2.97823682e+09\n",
      "  1.40940827e+09 -1.19471068e+09 -2.82127456e+09 -1.81889040e+08\n",
      " -1.74443067e+09 -2.97847453e+09 -1.02263805e+09 -2.24536823e+07\n",
      " -1.54404150e+07 -8.81077905e+08 -4.81331641e+07  3.93056038e+06\n",
      " -1.47739097e+09 -2.61448937e+07 -2.65295119e+09 -3.08840659e+09\n",
      " -2.51565702e+09 -2.40258011e+09 -2.40259336e+09 -2.99391553e+09\n",
      " -2.97846183e+09 -2.97844607e+09 -2.89829558e+09]\n",
      "Gradient Descent(61/99): loss=7.998152496062212e+20, weights = [-3.14672813e-01  1.11347698e+09 -1.13042724e+09 -1.63007937e+08\n",
      "  3.62337038e+09  4.32901869e+09  4.20072202e+09  4.32872852e+09\n",
      " -2.04850929e+09  1.73645634e+09  4.10059118e+09  2.64367248e+08\n",
      "  2.53544874e+09  4.32907402e+09  1.48635678e+09  3.26353816e+07\n",
      "  2.24419241e+07  1.28060570e+09  6.99593124e+07 -5.71288645e+06\n",
      "  2.14731897e+09  3.80003853e+07  3.85594099e+09  4.48885514e+09\n",
      "  3.65639032e+09  3.49203830e+09  3.49205755e+09  4.35151679e+09\n",
      "  4.32905556e+09  4.32903265e+09  4.21253765e+09]\n",
      "Gradient Descent(62/99): loss=1.6896312030722914e+21, weights = [-3.14648877e-01 -1.61838694e+09  1.64302334e+09  2.36924445e+08\n",
      " -5.26640010e+09 -6.29202705e+09 -6.10555382e+09 -6.29160530e+09\n",
      "  2.97741284e+09 -2.52385842e+09 -5.96001830e+09 -3.84245483e+08\n",
      " -3.68515666e+09 -6.29210747e+09 -2.16035036e+09 -4.74340072e+07\n",
      " -3.26182915e+07 -1.86130075e+09 -1.01682602e+08  8.30341440e+06\n",
      " -3.12102812e+09 -5.52317903e+07 -5.60443065e+09 -6.52434189e+09\n",
      " -5.31439304e+09 -5.07551504e+09 -5.07554302e+09 -6.32472699e+09\n",
      " -6.29208065e+09 -6.29204735e+09 -6.12272729e+09]\n",
      "Gradient Descent(63/99): loss=3.569391311057219e+21, weights = [-3.14684493e-01  2.35225005e+09 -2.38805791e+09 -3.44358647e+08\n",
      "  7.65446727e+09  9.14516828e+09  8.87413813e+09  9.14455529e+09\n",
      " -4.32753090e+09  3.66831067e+09  8.66260903e+09  5.58482914e+08\n",
      "  5.35620357e+09  9.14528517e+09  3.13996863e+09  6.89431203e+07\n",
      "  4.74091676e+07  2.70531395e+09  1.47790927e+08 -1.20686261e+07\n",
      "  4.53626902e+09  8.02768349e+07  8.14577895e+09  9.48282708e+09\n",
      "  7.72422278e+09  7.37702473e+09  7.37706540e+09  9.19269612e+09\n",
      "  9.14524618e+09  9.14519778e+09  8.89909897e+09]\n",
      "Gradient Descent(64/99): loss=7.540435041850841e+21, weights = [-3.14632797e-01 -3.41888589e+09  3.47093095e+09  5.00509255e+08\n",
      " -1.11254117e+10 -1.32920762e+10 -1.28981465e+10 -1.32911852e+10\n",
      "  6.28986462e+09 -5.33171871e+09 -1.25906988e+10 -8.11728906e+08\n",
      " -7.78499244e+09 -1.32922461e+10 -4.56379817e+09 -1.00205615e+08\n",
      " -6.89070172e+07 -3.93204783e+09 -2.14807229e+08  1.75411860e+07\n",
      " -6.59325576e+09 -1.16678641e+08 -1.18395103e+10 -1.37828475e+10\n",
      " -1.12267981e+10 -1.07221619e+10 -1.07222210e+10 -1.33611557e+10\n",
      " -1.32921894e+10 -1.32921191e+10 -1.29344259e+10]\n",
      "Gradient Descent(65/99): loss=1.5929371611410794e+22, weights = [-3.14708157e-01  4.96919142e+09 -5.04483649e+09 -7.27466893e+08\n",
      "  1.61702678e+10  1.93194137e+10  1.87468552e+10  1.93181187e+10\n",
      " -9.14202530e+09  7.74940484e+09  1.82999943e+10  1.17981016e+09\n",
      "  1.13151240e+10  1.93196606e+10  6.63326809e+09  1.45644194e+08\n",
      "  1.00153140e+08  5.71504840e+09  3.12212304e+08 -2.54952969e+07\n",
      "  9.58299018e+09  1.69586971e+08  1.72081769e+10  2.00327270e+10\n",
      "  1.63176282e+10  1.55841629e+10  1.55842488e+10  1.94198175e+10\n",
      "  1.93195783e+10  1.93194760e+10  1.87995857e+10]\n",
      "Gradient Descent(66/99): loss=3.3651225496418706e+22, weights = [-3.14597840e-01 -7.22248830e+09  7.33243489e+09  1.05733925e+09\n",
      " -2.35027311e+10 -2.80798681e+10 -2.72476810e+10 -2.80779859e+10\n",
      "  1.32875080e+10 -1.12633990e+10 -2.65981894e+10 -1.71479912e+09\n",
      " -1.64460057e+10 -2.80802270e+10 -9.64114625e+09 -2.11687053e+08\n",
      " -1.45567925e+08 -8.30655669e+09 -4.53786043e+08  3.70562267e+07\n",
      " -1.39284299e+10 -2.46486764e+08 -2.50112837e+10 -2.91166357e+10\n",
      " -2.37169126e+10 -2.26508550e+10 -2.26509799e+10 -2.82258004e+10\n",
      " -2.80801073e+10 -2.80799586e+10 -2.73243222e+10]\n",
      "Gradient Descent(67/99): loss=7.108911795363341e+22, weights = [-3.14758984e-01  1.04975504e+10 -1.06573526e+10 -1.53679336e+09\n",
      "  3.41601251e+10  4.08127805e+10  3.96032353e+10  4.08100449e+10\n",
      " -1.93127741e+10  1.63708259e+10  3.86592296e+10  2.49238066e+09\n",
      "  2.39035033e+10  4.08133021e+10  1.40129571e+10  3.07677273e+08\n",
      "  2.11576200e+08  1.20731933e+10  6.59556880e+08 -5.38594997e+07\n",
      "  2.02443242e+10  3.58257032e+08  3.63527360e+10  4.23196740e+10\n",
      "  3.44714279e+10  3.29219629e+10  3.29221444e+10  4.10248863e+10\n",
      "  4.08131281e+10  4.08129121e+10  3.97146298e+10]\n",
      "Gradient Descent(68/99): loss=1.501776715966395e+23, weights = [-3.14524542e-01 -1.52577006e+10  1.54899657e+10  2.23365757e+09\n",
      " -4.96501509e+10 -5.93194757e+10 -5.75614581e+10 -5.93154996e+10\n",
      "  2.80702177e+10 -2.37942331e+10 -5.61893898e+10 -3.62255922e+09\n",
      " -3.47426289e+10 -5.93202339e+10 -2.03671805e+10 -4.47194587e+08\n",
      " -3.07516153e+08 -1.75478242e+10 -9.58635208e+08  7.82822745e+07\n",
      " -2.94241824e+10 -5.20709910e+08 -5.28370087e+10 -6.15096752e+10\n",
      " -5.01026150e+10 -4.78505398e+10 -4.78508036e+10 -5.96277616e+10\n",
      " -5.93199810e+10 -5.93196670e+10 -5.77233648e+10]\n",
      "Gradient Descent(69/99): loss=3.172543660043443e+23, weights = [-3.14867400e-01  2.21763572e+10 -2.25139437e+10 -3.24651725e+09\n",
      "  7.21641820e+10  8.62180952e+10  8.36628986e+10  8.62123162e+10\n",
      " -4.07987541e+10  3.45838096e+10  8.16686612e+10  5.26522111e+09\n",
      "  5.04967930e+10  8.62191972e+10  2.96027483e+10  6.49976505e+08\n",
      "  4.46960406e+08  2.55049452e+10  1.39333163e+09 -1.13779640e+08\n",
      "  4.27666788e+10  7.56827604e+08  7.67961314e+10  8.94014482e+10\n",
      "  7.28218175e+10  6.95485311e+10  6.95489145e+10  8.66661745e+10\n",
      "  8.62188297e+10  8.62183734e+10  8.38982224e+10]\n",
      "Gradient Descent(70/99): loss=6.702083717155583e+23, weights = [-3.14380135e-01 -3.22323024e+10  3.27229687e+10  4.71866163e+09\n",
      " -1.04887278e+11 -1.25313986e+11 -1.21600127e+11 -1.25305586e+11\n",
      "  5.92990889e+10 -5.02659566e+10 -1.18701596e+11 -7.65275367e+09\n",
      " -7.33947369e+10 -1.25315588e+11 -4.30262159e+10 -9.44710579e+08\n",
      " -6.49636135e+08 -3.70702500e+10 -2.02514263e+09  1.65373408e+08\n",
      " -6.21593759e+10 -1.10001368e+09 -1.11619600e+11 -1.29940841e+11\n",
      " -1.05843120e+11 -1.01085551e+11 -1.01086108e+11 -1.25965248e+11\n",
      " -1.25315054e+11 -1.25314390e+11 -1.21942159e+11]\n",
      "Gradient Descent(71/99): loss=1.41583319143813e+24, weights = [-3.15105677e-01  4.68481504e+10 -4.75613110e+10 -6.85835492e+09\n",
      "  1.52448773e+11  1.82138043e+11  1.76740121e+11  1.82125834e+11\n",
      " -8.61884641e+10  7.30592269e+10  1.72527241e+11  1.11229211e+10\n",
      "  1.06675832e+11  1.82140371e+11  6.25366010e+10  1.37309283e+09\n",
      "  9.44215867e+08  5.38798820e+10  2.94345050e+09 -2.40362547e+08\n",
      "  9.03457580e+10  1.59881865e+09  1.62233891e+11  1.88862961e+11\n",
      "  1.53838046e+11  1.46923141e+11  1.46923950e+11  1.83084622e+11\n",
      "  1.82139594e+11  1.82138630e+11  1.77237249e+11]\n",
      "Gradient Descent(72/99): loss=2.9909856554711736e+24, weights = [-3.14066991e-01 -6.80916048e+10  6.91281506e+10  9.96829947e+09\n",
      " -2.21577192e+11 -2.64729162e+11 -2.56883535e+11 -2.64711418e+11\n",
      "  1.25270919e+11 -1.06188184e+11 -2.50760310e+11 -1.61666477e+10\n",
      " -1.55048354e+11 -2.64732546e+11 -9.08940372e+10 -1.99572648e+09\n",
      " -1.37237379e+09 -7.83118991e+10 -4.27816822e+09  3.49355768e+08\n",
      " -1.31313352e+11 -2.32380844e+09 -2.35799405e+11 -2.74503518e+11\n",
      " -2.23596435e+11 -2.13545942e+11 -2.13547119e+11 -2.66104971e+11\n",
      " -2.64731417e+11 -2.64730016e+11 -2.57606087e+11]\n",
      "Gradient Descent(73/99): loss=6.318537554658878e+24, weights = [-3.15560930e-01  9.89679763e+10 -1.00474547e+11 -1.44884590e+10\n",
      "  3.22052129e+11  3.84771508e+11  3.73368254e+11  3.84745718e+11\n",
      " -1.82075446e+11  1.54339580e+11  3.64468432e+11  2.34974696e+10\n",
      "  2.25355561e+11  3.84776426e+11  1.32110250e+11  2.90069549e+09\n",
      "  1.99468139e+09  1.13822698e+11  6.21811826e+09 -5.07772338e+08\n",
      "  1.90857841e+11  3.37754735e+09  3.42723453e+11  3.98978080e+11\n",
      "  3.24987005e+11  3.10379082e+11  3.10380793e+11  3.86771183e+11\n",
      "  3.84774786e+11  3.84772750e+11  3.74418450e+11]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Descent(74/99): loss=1.3348080341544065e+25, weights = [-3.13375521e-01 -1.43845344e+11  1.46035075e+11  2.10583004e+10\n",
      " -4.68087771e+11 -5.59247468e+11 -5.42673368e+11 -5.59209982e+11\n",
      "  2.64638181e+11 -2.24325391e+11 -5.29737891e+11 -3.41524777e+10\n",
      " -3.27543813e+11 -5.59254616e+11 -1.92016095e+11 -4.21602581e+09\n",
      " -2.89917650e+09 -1.65435991e+11 -9.03774531e+09  7.38023445e+08\n",
      " -2.77402983e+11 -4.90910777e+09 -4.98132578e+11 -5.79896058e+11\n",
      " -4.72353477e+11 -4.51121540e+11 -4.51124027e+11 -5.62153901e+11\n",
      " -5.59252232e+11 -5.59249272e+11 -5.44199780e+11]\n",
      "Gradient Descent(75/99): loss=2.8198178338425834e+25, weights = [-3.16514073e-01  2.09072509e+11 -2.12255181e+11 -3.06072590e+10\n",
      "  6.80343776e+11  8.12840149e+11  7.88750468e+11  8.12785665e+11\n",
      " -3.84639271e+11  3.26046509e+11  7.69949354e+11  4.96390358e+10\n",
      "  4.76069677e+11  8.12850538e+11  2.79086452e+11  6.12779716e+09\n",
      "  4.21381802e+09  2.40453508e+11  1.31359419e+10 -1.07268271e+09\n",
      "  4.03192317e+11  7.13515951e+09  7.24012502e+11  8.42851913e+11\n",
      "  6.86543780e+11  6.55684149e+11  6.55687763e+11  8.17064515e+11\n",
      "  8.12847073e+11  8.12842771e+11  7.90969035e+11]\n",
      "Gradient Descent(76/99): loss=5.956940932778972e+25, weights = [-3.11879337e-01 -3.03877155e+11  3.08503020e+11  4.44862254e+10\n",
      " -9.88847993e+11 -1.18142530e+12 -1.14641207e+12 -1.18134611e+12\n",
      "  5.59055267e+11 -4.73893416e+11 -1.11908553e+12 -7.21480267e+10\n",
      " -6.91945104e+11 -1.18144040e+12 -4.05639161e+11 -8.90646778e+09\n",
      " -6.12458824e+09 -3.49487975e+11 -1.90924798e+10  1.55909436e+09\n",
      " -5.86021255e+11 -1.03706221e+10 -1.05231845e+12 -1.22504600e+12\n",
      " -9.97859410e+11 -9.53006374e+11 -9.53011627e+11 -1.18756522e+12\n",
      " -1.18143536e+12 -1.18142911e+12 -1.14963666e+12]\n",
      "Gradient Descent(77/99): loss=1.2584197762967664e+26, weights = [-3.18605837e-01  4.41671292e+11 -4.48394772e+11 -6.46586569e+10\n",
      "  1.43724450e+12  1.71714665e+12  1.66625655e+12  1.71703156e+12\n",
      " -8.12560795e+11  6.88782009e+11  1.62653870e+12  1.04863797e+11\n",
      "  1.00570998e+12  1.71716860e+12  5.89577628e+11  1.29451361e+10\n",
      "  8.90180377e+09  5.07964496e+11  2.77500302e+10 -2.26607104e+09\n",
      "  8.51754601e+11  1.50732162e+10  1.52949586e+12  1.78054731e+12\n",
      "  1.45034218e+12  1.38515038e+12  1.38515802e+12  1.72607074e+12\n",
      "  1.71716128e+12  1.71715219e+12  1.67094334e+12]\n",
      "Gradient Descent(78/99): loss=2.658445586829081e+26, weights = [-3.08870971e-01 -6.41948654e+11  6.51720918e+11  9.39783464e+10\n",
      " -2.08896795e+12 -2.49579269e+12 -2.42182630e+12 -2.49562540e+12\n",
      "  1.18101927e+12 -1.00111257e+12 -2.36409824e+12 -1.52414645e+11\n",
      " -1.46175262e+12 -2.49582459e+12 -8.56923625e+11 -1.88151525e+10\n",
      " -1.29383572e+10 -7.38302738e+11 -4.03333765e+10  3.29362871e+09\n",
      " -1.23798565e+12 -2.19082177e+10 -2.22305100e+12 -2.58794259e+12\n",
      " -2.10800481e+12 -2.01325157e+12 -2.01326267e+12 -2.50876343e+12\n",
      " -2.49581395e+12 -2.49580074e+12 -2.42863832e+12]\n",
      "Gradient Descent(79/99): loss=5.6160377254468436e+26, weights = [-3.22897987e-01  9.33042471e+11 -9.47246002e+11 -1.36593150e+11\n",
      "  3.03621763e+12  3.62751844e+12  3.52001174e+12  3.62727529e+12\n",
      " -1.71655651e+12  1.45507050e+12  3.43610670e+12  2.21527588e+11\n",
      "  2.12458936e+12  3.62756480e+12  1.24549858e+12  2.73469479e+10\n",
      "  1.88052996e+10  1.07308864e+12  5.86226843e+10 -4.78713594e+09\n",
      "  1.79935448e+12  3.18425741e+10  3.23110110e+12  3.76145403e+12\n",
      "  3.06388682e+12  2.92616739e+12  2.92618352e+12  3.64637081e+12\n",
      "  3.62754934e+12  3.62753014e+12  3.52991269e+12]\n",
      "Gradient Descent(80/99): loss=1.1864030578584273e+27, weights = [-3.02167024e-01 -1.35613378e+12  1.37677795e+12  1.98531782e+11\n",
      " -4.41300092e+12 -5.27242911e+12 -5.11617312e+12 -5.27207570e+12\n",
      "  2.49493494e+12 -2.11487721e+12 -4.99422106e+12 -3.21980032e+11\n",
      " -3.08799169e+12 -5.27249650e+12 -1.81027418e+12 -3.97475151e+10\n",
      " -2.73326272e+10 -1.55968437e+12 -8.52053414e+10  6.95787915e+09\n",
      " -2.61527794e+12 -4.62816985e+10 -4.69625497e+12 -5.46709825e+12\n",
      " -4.45321680e+12 -4.25304803e+12 -4.25307147e+12 -5.29983015e+12\n",
      " -5.27247402e+12 -5.27244612e+12 -5.13056370e+12]\n",
      "Gradient Descent(81/99): loss=2.506308334287121e+27, weights = [-3.31951105e-01  1.97107729e+12 -2.00108263e+12 -2.88556699e+11\n",
      "  6.41409132e+12  7.66323016e+12  7.43611936e+12  7.66271650e+12\n",
      " -3.62627174e+12  3.07387552e+12  7.25886771e+12  4.67982981e+11\n",
      "  4.48825210e+12  7.66332811e+12  2.63114921e+12  5.77711621e+10\n",
      "  3.97267007e+10  2.26692859e+12  1.23841996e+11 -1.01129533e+10\n",
      "  3.80118468e+12  6.72682933e+10  6.82578789e+12  7.94617270e+12\n",
      "  6.47254322e+12  6.18160723e+12  6.18164131e+12  7.70305630e+12\n",
      "  7.66329544e+12  7.66325488e+12  7.45703540e+12]\n",
      "Gradient Descent(82/99): loss=5.294643692048307e+27, weights = [-2.87966918e-01 -2.86486904e+12  2.90848041e+12  4.19403723e+11\n",
      " -9.32258301e+12 -1.11381481e+13 -1.08080532e+13 -1.11374016e+13\n",
      "  5.27061710e+12 -4.46773492e+12 -1.05504262e+13 -6.80191468e+11\n",
      " -6.52346540e+12 -1.11382905e+13 -3.82425284e+12 -8.39676935e+10\n",
      " -5.77409093e+10 -3.29487513e+12 -1.79998573e+11  1.46987066e+10\n",
      " -5.52484490e+12 -9.77713315e+10 -9.92096480e+12 -1.15493919e+13\n",
      " -9.40754013e+12 -8.98467822e+12 -8.98472775e+12 -1.11960336e+13\n",
      " -1.11382430e+13 -1.11381841e+13 -1.08384537e+13]\n",
      "Gradient Descent(83/99): loss=1.1185077048279902e+28, weights = [-3.51315443e-01  4.16395373e+12 -4.22734082e+12 -6.09583779e+11\n",
      "  1.35499402e+13  1.61887796e+13  1.57090019e+13  1.61876945e+13\n",
      " -7.66059648e+12  6.49364463e+12  1.53345531e+13  9.88626620e+11\n",
      "  9.48155315e+12  1.61889865e+13  5.55837340e+12  1.22043132e+11\n",
      "  8.39237226e+10  4.78894756e+12  2.61619543e+11 -2.13638855e+10\n",
      "  8.03010476e+12  1.42106077e+11  1.44196603e+13  1.67865033e+13\n",
      "  1.36734215e+13  1.30588114e+13  1.30588833e+13  1.62729134e+13\n",
      "  1.61889175e+13  1.61888318e+13  1.57531876e+13]\n",
      "Gradient Descent(84/99): loss=2.362877576896153e+28, weights = [-2.58462443e-01 -6.05211282e+12  6.14424300e+12  8.86001632e+11\n",
      " -1.96942071e+13 -2.35296372e+13 -2.28323027e+13 -2.35280600e+13\n",
      "  1.11343202e+13 -9.43821004e+12 -2.22880587e+13 -1.43692275e+12\n",
      " -1.37809959e+13 -2.35299379e+13 -8.07883687e+12 -1.77384009e+11\n",
      " -1.21979222e+11 -6.96051224e+12 -3.80251821e+11  3.10514127e+10\n",
      " -1.16713833e+13 -2.06544565e+11 -2.09583047e+13 -2.43984008e+13\n",
      " -1.98736813e+13 -1.89803741e+13 -1.89804788e+13 -2.36519218e+13\n",
      " -2.35298376e+13 -2.35297131e+13 -2.28965245e+13]\n",
      "Gradient Descent(85/99): loss=4.991642363569831e+28, weights = [-3.93338343e-01  8.79646412e+12 -8.93037105e+12 -1.28776211e+12\n",
      "  2.86246128e+13  3.41992318e+13  3.31856886e+13  3.41969395e+13\n",
      " -1.61832159e+13  1.37179987e+13  3.23946553e+13  2.08850030e+12\n",
      "  2.00300358e+13  3.41996689e+13  1.17422131e+13  2.57819395e+11\n",
      "  1.77291119e+11  1.01167804e+13  5.52678313e+11 -4.51317822e+10\n",
      "  1.69638120e+13  3.00202905e+11  3.04619198e+13  3.54619392e+13\n",
      "  2.88854702e+13  2.75870898e+13  2.75872419e+13  3.43769667e+13\n",
      "  3.41995232e+13  3.41993422e+13  3.32790321e+13]\n",
      "Gradient Descent(86/99): loss=1.0544978601267587e+29, weights = [-2.00999643e-01 -1.27852509e+13  1.29798784e+13  1.87170225e+12\n",
      " -4.16045416e+13 -4.97069907e+13 -4.82338529e+13 -4.97036589e+13\n",
      "  2.35215506e+13 -1.99384723e+13 -4.70841228e+13 -3.03553791e+12\n",
      " -2.91127241e+13 -4.97076261e+13 -1.70667599e+13 -3.74728484e+11\n",
      " -2.57684384e+11 -1.47042691e+13 -8.03292188e+11  6.55969435e+10\n",
      " -2.46561108e+13 -4.36330942e+11 -4.42749817e+13 -5.15422771e+13\n",
      " -4.19836856e+13 -4.00965503e+13 -4.00967713e+13 -4.99653202e+13\n",
      " -4.97074142e+13 -4.97071511e+13 -4.83695233e+13]\n",
      "Gradient Descent(87/99): loss=2.2276550602409192e+29, weights = [-4.84869243e-01  1.85827668e+13 -1.88656488e+13 -2.72043205e+12\n",
      "  6.04702635e+13  7.22467961e+13  7.01056588e+13  7.22419535e+13\n",
      " -3.41874784e+13  2.89796409e+13  6.84345797e+13  4.41201299e+12\n",
      "  4.23139887e+13  7.22477195e+13  2.48057407e+13  5.44650399e+11\n",
      "  3.74532251e+11  2.13719703e+13  1.16754778e+12 -9.53421024e+10\n",
      "  3.58365087e+13  6.34186703e+11  6.43516240e+13  7.49142994e+13\n",
      "  6.10213318e+13  5.82784685e+13  5.82787897e+13  7.26222658e+13\n",
      "  7.22474115e+13  7.22470291e+13  7.03028494e+13]\n",
      "Gradient Descent(88/99): loss=4.7059811641726466e+29, weights = [-6.81151429e-02 -2.70091861e+13  2.74203419e+13  3.95402129e+12\n",
      " -8.78907118e+13 -1.05007353e+14 -1.01895310e+14 -1.05000315e+14\n",
      "  4.96899076e+13 -4.21205584e+13 -9.94664745e+13 -6.41265540e+12\n",
      " -6.15014119e+13 -1.05008696e+14 -3.60539889e+13 -7.91623990e+11\n",
      " -5.44365185e+11 -3.10631636e+13 -1.69697633e+12  1.38575305e+11\n",
      " -5.20866964e+13 -9.21760838e+11 -9.35320884e+13 -1.08884445e+14\n",
      " -8.86916639e+13 -8.47050398e+13 -8.47055067e+13 -1.05553081e+14\n",
      " -1.05008248e+14 -1.05007692e+14 -1.02181917e+14]\n",
      "Gradient Descent(89/99): loss=9.941511642809325e+29, weights = [-6.65670343e-01  3.92565941e+13 -3.98541899e+13 -5.74698580e+12\n",
      "  1.27745056e+14  1.52623298e+14  1.48100088e+14  1.52613068e+14\n",
      " -7.22219665e+13  6.12202700e+13  1.44569888e+14  9.32049597e+12\n",
      "  8.93894379e+13  1.52625248e+14  5.24027937e+13  1.15058860e+12\n",
      "  7.91209443e+11  4.51488615e+13  2.46647606e+12 -2.01412753e+11\n",
      "  7.57055875e+13  1.33973645e+12  1.35944535e+14  1.58258470e+14\n",
      "  1.28909203e+14  1.23114830e+14  1.23115509e+14  1.53416488e+14\n",
      "  1.52624598e+14  1.52623790e+14  1.48516658e+14]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Descent(90/99): loss=2.100171043958862e+30, weights = [ 2.16660657e-01 -5.70576312e+13  5.79262089e+13  8.35297621e+12\n",
      " -1.85671490e+14 -2.21830855e+14 -2.15256580e+14 -2.21815986e+14\n",
      "  1.04971265e+14 -8.89808112e+13 -2.10125600e+14 -1.35469068e+13\n",
      " -1.29923385e+14 -2.21833690e+14 -7.61650202e+13 -1.67232695e+12\n",
      " -1.14998608e+12 -6.56217676e+13 -3.58490809e+12  2.92744056e+11\n",
      " -1.10034546e+14 -1.94724453e+12 -1.97589050e+14 -2.30021316e+14\n",
      " -1.87363523e+14 -1.78941672e+14 -1.78942659e+14 -2.22983720e+14\n",
      " -2.21832745e+14 -2.21831571e+14 -2.15862046e+14]\n",
      "Gradient Descent(91/99): loss=4.436667754720795e+30, weights = [-1.05465694e+00  8.29306097e+13 -8.41930469e+13 -1.21406619e+13\n",
      "  2.69864864e+14  3.22420817e+14  3.12865414e+14  3.22399205e+14\n",
      " -1.52570845e+14  1.29329465e+14  3.05407773e+14  1.96897981e+13\n",
      "  1.88837589e+14  3.22424938e+14  1.10702310e+14  2.43064933e+12\n",
      "  1.67145121e+12  9.53781830e+13  5.21049695e+12 -4.25489851e+11\n",
      "  1.59930087e+14  2.83022924e+12  2.87186482e+14  3.34325270e+14\n",
      "  2.72324154e+14  2.60083387e+14  2.60084821e+14  3.24096452e+14\n",
      "  3.22423563e+14  3.22421857e+14  3.13745430e+14]\n",
      "Gradient Descent(92/99): loss=9.372579829819021e+30, weights = [ 7.92429457e-01 -1.20535779e+14  1.22370673e+14  1.76458867e+13\n",
      " -3.92236011e+14 -4.68623641e+14 -4.54735309e+14 -4.68592230e+14\n",
      "  2.21754617e+14 -1.87974354e+14 -4.43895975e+14 -2.86182046e+13\n",
      " -2.74466641e+14 -4.68629631e+14 -1.60900651e+14 -3.53283560e+12\n",
      " -2.42937649e+12 -1.38627747e+14 -7.57321465e+12  6.18429683e+11\n",
      " -2.32450934e+14 -4.11360639e+12 -4.17412176e+14 -4.85926210e+14\n",
      " -3.95810476e+14 -3.78019090e+14 -3.78021174e+14 -4.71059099e+14\n",
      " -4.68627633e+14 -4.68625153e+14 -4.56014371e+14]\n",
      "Gradient Descent(93/99): loss=1.9799826699409887e+31, weights = [-1.88229054e+00  1.75193141e+14 -1.77860074e+14 -2.56474745e+13\n",
      "  5.70096775e+14  6.81122638e+14  6.60936594e+14  6.81076983e+14\n",
      " -3.22310008e+14  2.73211970e+14  6.45182126e+14  4.15952276e+13\n",
      "  3.98924481e+14  6.81131344e+14  2.33861603e+14  5.13481202e+12\n",
      "  3.53098558e+12  2.01488974e+14  1.10073148e+13 -8.98858743e+11\n",
      "  3.37856607e+14  5.97893531e+12  6.06689158e+14  7.06271115e+14\n",
      "  5.75292093e+14  5.49433142e+14  5.49436171e+14  6.84662462e+14\n",
      "  6.81128440e+14  6.81124835e+14  6.62795651e+14]\n",
      "Gradient Descent(94/99): loss=4.182766585560677e+31, weights = [ 2.01099426e+00 -2.54635071e+14  2.58511333e+14  3.72774097e+13\n",
      " -8.28609111e+14 -9.89980033e+14 -9.60640557e+14 -9.89913676e+14\n",
      "  4.68462586e+14 -3.97100874e+14 -9.37742172e+14 -6.04567261e+13\n",
      " -5.79818154e+14 -9.89992686e+14 -3.39906949e+14 -7.46321013e+12\n",
      " -5.13212309e+12 -2.92854840e+14 -1.59986194e+13  1.30644932e+12\n",
      " -4.91058843e+14 -8.69010402e+12 -8.81794436e+14 -1.02653217e+15\n",
      " -8.36160264e+14 -7.98575484e+14 -7.98579886e+14 -9.95125003e+14\n",
      " -9.89988466e+14 -9.89983227e+14 -9.63342611e+14]\n",
      "Gradient Descent(95/99): loss=8.83620678851905e+31, weights = [-3.59446814e+00  3.70100217e+14 -3.75734184e+14 -5.41809789e+13\n",
      "  1.20434475e+15  1.43888987e+15  1.39624631e+15  1.43879343e+15\n",
      " -6.80888552e+14  5.77167626e+14  1.36296457e+15  8.78710358e+13\n",
      "  8.42738683e+14  1.43890826e+15  4.94038920e+14  1.08474283e+13\n",
      "  7.45930190e+12  4.25650871e+14  2.32532482e+13 -1.89886324e+12\n",
      "  7.13731158e+14  1.26306615e+13  1.28164715e+15  1.49201671e+15\n",
      "  1.21532000e+15  1.16069227e+15  1.16069867e+15  1.44636785e+15\n",
      "  1.43890213e+15  1.43889451e+15  1.40017362e+15]\n",
      "Gradient Descent(96/99): loss=1.86667242391686e+32, weights = [ 4.46583906e+00 -5.37923429e+14  5.46112137e+14  7.87495294e+13\n",
      " -1.75045901e+15 -2.09135942e+15 -2.02937899e+15 -2.09121924e+15\n",
      "  9.89639800e+14 -8.38886265e+14 -1.98100553e+15 -1.27716458e+14\n",
      " -1.22488143e+15 -2.09138615e+15 -7.18062562e+14 -1.57662319e+13\n",
      " -1.08417479e+13 -6.18663718e+14 -3.37975133e+13  2.75990929e+12\n",
      " -1.03737500e+15 -1.83580782e+13 -1.86281444e+15 -2.16857679e+15\n",
      " -1.76641102e+15 -1.68701216e+15 -1.68702146e+15 -2.10222830e+15\n",
      " -2.09137723e+15 -2.09136616e+15 -2.03508715e+15]\n",
      "Gradient Descent(97/99): loss=3.9433956465788175e+32, weights = [-7.34235934e+00  7.81846652e+14 -7.93748558e+14 -1.14458774e+14\n",
      "  2.54421065e+15  3.03969351e+15  2.94960784e+15  3.03948977e+15\n",
      " -1.43839536e+15  1.21928212e+15  2.87929928e+15  1.85629924e+14\n",
      "  1.78030811e+15  3.03973236e+15  1.04367049e+15  2.29154838e+13\n",
      "  1.57579757e+13  8.99198901e+14  4.91231116e+13 -4.01139962e+12\n",
      "  1.50777625e+15  2.66826117e+13  2.70751403e+15  3.15192538e+15\n",
      "  2.56739616e+15  2.45199361e+15  2.45200713e+15  3.05549093e+15\n",
      "  3.03971941e+15  3.03970332e+15  2.95790439e+15]\n",
      "Gradient Descent(98/99): loss=8.330529248847879e+32, weights = [ 1.03868951e+01 -1.13637770e+15  1.15367656e+15  1.66360497e+14\n",
      " -3.69789169e+15 -4.41805296e+15 -4.28711763e+15 -4.41775682e+15\n",
      "  2.09064067e+15 -1.77216977e+15 -4.18492741e+15 -2.69804449e+14\n",
      " -2.58759492e+15 -4.41810942e+15 -1.51692645e+15 -3.33065885e+13\n",
      " -2.29034838e+13 -1.30694372e+15 -7.13981549e+13  5.83038252e+12\n",
      " -2.19148256e+15 -3.87819335e+13 -3.93524555e+15 -4.58117674e+15\n",
      " -3.73159074e+15 -3.56385852e+15 -3.56387817e+15 -4.44101377e+15\n",
      " -4.41809059e+15 -4.41806721e+15 -4.29917627e+15]\n",
      "Gradient Descent(99/99): loss=1.7598466850800822e+33, weights = [-1.46704873e+01  1.65167206e+15 -1.67681515e+15 -2.41797234e+14\n",
      "  5.37471335e+15  6.42143421e+15  6.23112582e+15  6.42100379e+15\n",
      " -3.03864884e+15  2.57576623e+15  6.08259709e+15  3.92148201e+14\n",
      "  3.76094871e+15  6.42151629e+15  2.20478195e+15  4.84095752e+13\n",
      "  3.32891470e+13  1.89958184e+15  1.03773893e+14 -8.47418946e+12\n",
      "  3.18521783e+15  5.63677341e+13  5.71969613e+15  6.65852704e+15\n",
      "  5.42369335e+15  5.17990239e+15  5.17993094e+15  6.45480669e+15\n",
      "  6.42148891e+15  6.42145493e+15  6.24865249e+15]\n"
     ]
    }
   ],
   "source": [
    "w_initial = np.random.rand(num_features)\n",
    "max_iters = 100\n",
    "gamma = 0.2\n",
    "\n",
    "weights, loss = least_squares_GD (y, tx, w_initial, max_iters, gamma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Look for the best value of gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Best value of gamma = 0.15000000000000002 \n",
      " Loss = 0.3429823819412409 \n",
      " Weights = [-0.31466396  0.04219054 -0.26894748 -0.21610405 -0.09000959  0.54347465\n",
      "  0.25807863 -0.32558529  0.22600166 -0.00297263  0.05446148 -0.05584056\n",
      "  0.12530421  0.18316699  0.2472199  -0.00071133 -0.00159896  0.16544071\n",
      " -0.00120878  0.00245969  0.14584134  0.00095637 -0.04171631 -0.23681485\n",
      "  0.22590384 -0.04805708  0.00156729 -0.04710753 -0.06446058 -0.29451245\n",
      " -0.16189047]\n"
     ]
    }
   ],
   "source": [
    "w_initial = np.random.rand(num_features)\n",
    "max_iters = 100\n",
    "gammas = np.arange(0.01, 0.16, 0.01)\n",
    "ws = []\n",
    "losses = []\n",
    "\n",
    "for ind, gamma in enumerate(gammas):\n",
    "    w, l = least_squares_GD(y, tx, w_initial, max_iters, gamma, printing=False)\n",
    "    ws.append(w)\n",
    "    losses.append(l)\n",
    "\n",
    "loss = np.amin(losses)\n",
    "weights = ws[np.argmin(losses)]\n",
    "gamma_star = gammas[np.argmin(losses)]\n",
    "\n",
    "plt.plot(gammas, losses, color='k')\n",
    "plt.plot(gamma_star, loss, 'r*', markersize=15, label=\"Minimal loss\")\n",
    "plt.xlabel('Gamma')\n",
    "plt.ylabel('Loss')\n",
    "plt.title(\"Loss in function of gamma\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "print(\" Best value of gamma = {g} \\n Loss = {l} \\n Weights = {we}\".format(\n",
    "    g=gamma_star, l=loss, we = weights))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate predictions and save ouput in csv format for submission:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_TEST_PATH = 'data/test.csv'\n",
    "_, tX_test, ids_test = load_csv_data(DATA_TEST_PATH)\n",
    "_, tx_test = build_model_data(tX_test,ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_PATH = 'data/submission.csv'\n",
    "y_pred = predict_labels(weights, tX_test)\n",
    "create_csv_submission(ids_test, y_pred, OUTPUT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
