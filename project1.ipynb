{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "S_s6B33VEndZ"
   },
   "outputs": [],
   "source": [
    "# Useful starting lines\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YaBZH_VLEndi"
   },
   "source": [
    "## Load the training data into feature matrix, class labels, and event ids:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QUp3aGWvqm3j"
   },
   "outputs": [],
   "source": [
    "from proj1_helpers import *\n",
    "from data_helpers import *\n",
    "from implementations import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pgWxh_GdEndl"
   },
   "outputs": [],
   "source": [
    "DATA_TRAIN_PATH = 'data/train.csv'\n",
    "y, tX, ids = load_csv_data(DATA_TRAIN_PATH)\n",
    "tx, mean, std = standardize(tX,0)\n",
    "y, tx = build_model_data(tx,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-jv3lZU9hlEw",
    "outputId": "fd436073-e0fd-40c4-efb2-bdae44420cbf"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(250000, 31)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_samples = len(y)\n",
    "num_features = tx.shape[1]\n",
    "\n",
    "num_samples, num_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ReKwkQ-cEnds"
   },
   "source": [
    "## Do your thing crazy machine learning thing here :) ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 232
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 544,
     "status": "error",
     "timestamp": 1571295874514,
     "user": {
      "displayName": "Sofia Dandjee",
      "photoUrl": "",
      "userId": "04011238111956572445"
     },
     "user_tz": -120
    },
    "id": "b2HFZUfIxCgX",
    "outputId": "eea2b54a-30c0-4fc8-ef35-8cf93c297fb4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Descent(0/29): loss=25.553883100927553, weights = [ 0.2071984   0.09480354  0.76106035  0.3289904  -0.20686911 -0.45943649\n",
      " -0.01141789 -0.28818147  0.52988447 -0.03035608 -0.06762286  0.37757835\n",
      "  0.22259781  0.19919503  0.30070133  0.00383268  0.54098388  0.62750603\n",
      "  0.36162248  0.49877846 -0.27317567  0.12059608  0.22107656 -0.33292624\n",
      "  0.27583003  0.13519048 -0.29522324 -0.46110766 -0.20444789  0.26004502\n",
      " -0.07382725]\n",
      "Gradient Descent(1/29): loss=3.57862973696371, weights = [ 0.15501216  0.12326294  0.60858919  0.20398292 -0.09362406 -0.30896484\n",
      "  0.13981601 -0.13785945  0.41133109  0.00724438  0.02764626  0.26934318\n",
      "  0.32070101  0.349626    0.34364538 -0.01614779  0.4979385   0.52713507\n",
      "  0.32672461  0.46049861 -0.20524275  0.10804966  0.31423265 -0.19353042\n",
      "  0.37818668  0.23239233 -0.1979406  -0.31050402 -0.05403543  0.410479\n",
      "  0.05141225]\n",
      "Gradient Descent(2/29): loss=1.8141667862670652, weights = [ 0.10804455  0.10878487  0.52261807  0.11052457 -0.11829122 -0.33032044\n",
      "  0.12389739 -0.1593339   0.38332781 -0.01843351 -0.02827625  0.17821238\n",
      "  0.31425541  0.32823416  0.32812721 -0.03323581  0.45753806  0.40958694\n",
      "  0.29403742  0.425228   -0.21677591  0.09543553  0.26338358 -0.22904203\n",
      "  0.34021756  0.1953922  -0.2348685  -0.33244952 -0.07544249  0.38909184\n",
      "  0.01540686]\n",
      "Gradient Descent(3/29): loss=1.3206068813902974, weights = [ 0.06577369  0.1046941   0.44416907  0.0355152  -0.10885279 -0.31593969\n",
      "  0.14229434 -0.14505939  0.34597506 -0.0255284  -0.04158501  0.11050396\n",
      "  0.32574599  0.34258423  0.32537133 -0.04655718  0.42057497  0.32860177\n",
      "  0.26617126  0.3925216  -0.20661855  0.08445105  0.25119332 -0.22491356\n",
      "  0.33626784  0.19078951 -0.23940576 -0.31834847 -0.06110573  0.40344612\n",
      "  0.01855729]\n",
      "Gradient Descent(4/29): loss=1.0354944393562764, weights = [ 0.02772992  0.09898647  0.38164172 -0.02346168 -0.10529671 -0.31209049\n",
      "  0.15015862 -0.14130405  0.31977821 -0.03364943 -0.05823801  0.05848758\n",
      "  0.32878262  0.34640655  0.31946115 -0.05704303  0.38654836  0.2645765\n",
      "  0.24174884  0.36227199 -0.19902719  0.07457064  0.2347741  -0.22965215\n",
      "  0.32649591  0.18059596 -0.24954018 -0.3147438  -0.05729502  0.40727245\n",
      "  0.01466321]\n",
      "Gradient Descent(5/29): loss=0.850165033445937, weights = [-0.00650947  0.09439211  0.32929924 -0.0700989  -0.09926737 -0.3076838\n",
      "  0.15829243 -0.13698207  0.29834453 -0.03913755 -0.06934965  0.01905708\n",
      "  0.33040726  0.35078942  0.31418007 -0.06510039  0.35527538  0.21622209\n",
      "  0.22041663  0.33430104 -0.18944255  0.06577882  0.22273721 -0.232175\n",
      "  0.31966521  0.17322291 -0.25685971 -0.31051428 -0.05292241  0.41165897\n",
      "  0.013639  ]\n",
      "Gradient Descent(6/29): loss=0.7259905498005379, weights = [-0.03732492  0.09025391  0.28548534 -0.10690044 -0.09316601 -0.3047813\n",
      "  0.16473108 -0.13415697  0.28170718 -0.04341198 -0.07810079 -0.01083113\n",
      "  0.32983551  0.35367045  0.30879986 -0.07115779  0.32652408  0.17939889\n",
      "  0.20169046  0.30845436 -0.17955992  0.0579521   0.21229093 -0.23494626\n",
      "  0.31355672  0.16657803 -0.26345609 -0.30775106 -0.05005054  0.41454323\n",
      "  0.01282814]\n",
      "Gradient Descent(7/29): loss=0.6406625823477069, weights = [-0.06505883  0.08665727  0.24829112 -0.13593328 -0.08680501 -0.30257388\n",
      "  0.17029052 -0.1320212   0.26870949 -0.0465924  -0.08465604 -0.03337699\n",
      "  0.32786872  0.35585824  0.30357981 -0.07555644  0.30009493  0.15161917\n",
      "  0.1852018   0.28458122 -0.16945375  0.05099995  0.2034359  -0.23738387\n",
      "  0.30847406  0.1609677  -0.26902246 -0.30565446 -0.04787101  0.41673381\n",
      "  0.01253703]\n",
      "Gradient Descent(8/29): loss=0.5804418459203393, weights = [-0.09001935  0.08350767  0.21638179 -0.15880812 -0.08047394 -0.30098713\n",
      "  0.17506933 -0.1305015   0.25868219 -0.04898189 -0.0896503  -0.05030942\n",
      "  0.32480417  0.35742681  0.29852776 -0.07858758  0.27580075  0.1307977\n",
      "  0.17062873  0.26253977 -0.15941936  0.04483321  0.19569623 -0.23961356\n",
      "  0.3041771   0.15617157 -0.27377869 -0.30415959 -0.04630997  0.41830469\n",
      "  0.01248383]\n",
      "Gradient Descent(9/29): loss=0.5367484263511393, weights = [-0.11248381  0.08074884  0.18868988 -0.17680226 -0.07427423 -0.29984345\n",
      "  0.17926238 -0.12942118  0.25102267 -0.05075862 -0.09344919 -0.0629528\n",
      "  0.32094264  0.35855346  0.29368718 -0.0804948   0.25346983  0.11535856\n",
      "  0.15770044  0.24219621 -0.14959663  0.03937129  0.18882253 -0.24161193\n",
      "  0.30057338  0.15210515 -0.27780886 -0.30309506 -0.04519026  0.41943319\n",
      "  0.01258172]\n",
      "Gradient Descent(10/29): loss=0.5041636883690864, weights = [-0.13270183  0.07831877  0.16439311 -0.19092469 -0.06829215 -0.29903653\n",
      "  0.1829921  -0.12867466  0.24525728 -0.05206674 -0.09635569 -0.07232846\n",
      "  0.31649918  0.35934424  0.28907706 -0.08148267  0.23294385  0.10407459\n",
      "  0.14618674  0.22342504 -0.1400856   0.0345403   0.18260347 -0.24339657\n",
      "  0.29755789  0.14866856 -0.28121251 -0.3023591  -0.04440592  0.42022537\n",
      "  0.012745  ]\n",
      "Gradient Descent(11/29): loss=0.47922041329479254, weights = [-0.15089805  0.07616284  0.14284914 -0.20197427 -0.06257591 -0.29848013\n",
      "  0.18635867 -0.12817622  0.2410002  -0.05301152 -0.09859287 -0.07922174\n",
      "  0.31164307  0.35988524  0.28470943 -0.08172253  0.21407706  0.09599846\n",
      "  0.13589237  0.20610887 -0.13094241  0.03027313  0.17688655 -0.24498001\n",
      "  0.29504653  0.14577954 -0.28407155 -0.30186857 -0.04387095  0.42076733\n",
      "  0.0129208 ]\n",
      "Gradient Descent(12/29): loss=0.4596654238708832, weights = [-0.16727464  0.07423239  0.12355631 -0.21058388 -0.05715295 -0.29811077\n",
      "  0.18943774 -0.12786282  0.23794072 -0.0536723  -0.10033043 -0.08423631\n",
      "  0.30650387  0.36023978  0.2805885  -0.08135777  0.19673534  0.09039693\n",
      "  0.12665149  0.19013816 -0.12219626  0.02650896  0.17155675 -0.24637814\n",
      "  0.29296592  0.14336469 -0.28645911 -0.30156215 -0.0435221   0.4211224\n",
      "  0.01307292]\n",
      "Gradient Descent(13/29): loss=0.4440079463034596, weights = [-0.18201358  0.07248556  0.10612113 -0.21725545 -0.05203478 -0.29788047\n",
      "  0.19228796 -0.1276868   0.23582823 -0.05410843 -0.1016959  -0.08783555\n",
      "  0.30118164  0.36045577  0.27671329 -0.08050822  0.18079527  0.08670288\n",
      "  0.11832319  0.17541093 -0.1138572   0.02319287  0.16652877 -0.2476069\n",
      "  0.2912535   0.14136013 -0.28843881 -0.30139325 -0.04331153  0.42133851\n",
      "  0.01317869]\n",
      "Gradient Descent(14/29): loss=0.43124140656380067, weights = [-0.19527862  0.07088691  0.09023377 -0.22238743 -0.04722233 -0.29775327\n",
      "  0.19495451 -0.12761247  0.23446096 -0.05436458 -0.10278518 -0.09037472\n",
      "  0.29575344  0.36056905  0.2730789  -0.07927383  0.16614331  0.08447755\n",
      "  0.11078762  0.16183238 -0.1059227   0.02027538  0.16173926 -0.24868209\n",
      "  0.28985565  0.13971007 -0.29006619 -0.30132683 -0.04320342  0.42145155\n",
      "  0.0132248 ]\n",
      "Gradient Descent(15/29): loss=0.4206708875431981, weights = [-0.20721716  0.06940704  0.07564914 -0.22629646 -0.04270941 -0.29770223\n",
      "  0.19747242 -0.12761309  0.23367669 -0.05447447 -0.10367015 -0.09212566\n",
      "  0.29027864  0.36060652  0.26967774 -0.07773786  0.15267509  0.08338152\n",
      "  0.1039427   0.14931452 -0.09838208  0.01771203  0.15714136 -0.24961882\n",
      "  0.28872642  0.138366   -0.29138957 -0.30133648 -0.04317094  0.42148842\n",
      "  0.01320455]\n",
      "Gradient Descent(16/29): loss=0.41180523621057985, weights = [-0.21796184  0.06802188  0.06217237 -0.22923441 -0.03848528 -0.29770719\n",
      "  0.19986884 -0.12766867  0.23334521 -0.05446374 -0.10440452 -0.09329597\n",
      "  0.28480296  0.36058828  0.26650033 -0.0759695   0.1402946   0.0831522\n",
      "  0.09770147  0.13777576 -0.0912197   0.01546291  0.15270054 -0.25043128\n",
      "  0.28782645  0.13728572 -0.29245094 -0.30140232 -0.043194    0.42146924\n",
      "  0.0131158 ]\n",
      "Gradient Descent(17/29): loss=0.40428893053611475, weights = [-0.22763206  0.06671209  0.04964756 -0.23140188 -0.03453647 -0.29775312\n",
      "  0.20216494 -0.12776428  0.23336215 -0.05435206 -0.10502828 -0.09404379\n",
      "  0.27936149  0.36052934  0.26353605 -0.07402612  0.12891364  0.08358649\n",
      "  0.09198967  0.12714053 -0.08441714  0.01349232  0.14839144 -0.25113261\n",
      "  0.28712202  0.13643262 -0.29328675 -0.30150941 -0.04325762  0.42140905\n",
      "  0.0129595 ]\n",
      "Gradient Descent(18/29): loss=0.39785854807909526, weights = [-0.23633525  0.06546232  0.03794923 -0.23295873 -0.03084802 -0.2978288\n",
      "  0.20437725 -0.12788883  0.23364409 -0.05415466 -0.10557106 -0.09448917\n",
      "  0.27398109  0.36044086  0.26077361 -0.07195519  0.1184511   0.08452729\n",
      "  0.08674384  0.1173389  -0.07795473  0.0117683   0.14419551 -0.25173479\n",
      "  0.28658421  0.13577496 -0.29392861 -0.30164654 -0.04335065  0.42131905\n",
      "  0.01273862]\n",
      "Gradient Descent(19/29): loss=0.3923145681738538, weights = [-0.24416813  0.06426061  0.02697562 -0.23403255 -0.0274044  -0.29792592\n",
      "  0.20651874 -0.12803407  0.23412446 -0.05388351 -0.10605472 -0.09472293\n",
      "  0.26868222  0.36033116  0.25820142 -0.06979583  0.1088325   0.08585312\n",
      "  0.08190963  0.10830618 -0.07181252  0.01026234  0.14009921 -0.25224874\n",
      "  0.2861882   0.13528521 -0.2944039  -0.30180528 -0.04346482  0.42120756\n",
      "  0.01245735]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Descent(20/29): loss=0.38750281446353313, weights = [-0.25121772  0.06309782  0.01664358 -0.23472523 -0.0241901  -0.29803831\n",
      "  0.20859964 -0.12819391  0.23475032 -0.05354818 -0.10649525 -0.09481345\n",
      "  0.26348033  0.36020637  0.2558079  -0.06758016  0.09998935  0.08747004\n",
      "  0.07744044  0.09998258 -0.06597093  0.00894899  0.13609273 -0.25268426\n",
      "  0.28591271  0.13493952 -0.29473634 -0.30197936 -0.04359398  0.42108074\n",
      "  0.01212062]\n",
      "Gradient Descent(21/29): loss=0.3833020211859912, weights = [-0.25756234  0.06196709  0.00688459 -0.23511822 -0.02119    -0.29816143\n",
      "  0.21062805 -0.12836386  0.2354797  -0.05315646 -0.10690427 -0.09481186\n",
      "  0.25838692  0.36007103  0.25358169 -0.06533447  0.09185877  0.08930545\n",
      "  0.07329619  0.09231285 -0.06041116  0.00780559  0.13216892 -0.25305018\n",
      "  0.28573946  0.13471725 -0.29494647 -0.30216405 -0.04373362  0.42094314\n",
      "  0.01173363]\n",
      "Gradient Descent(22/29): loss=0.3796153368774633, weights = [-0.26327251  0.06086342 -0.00235832 -0.23527669 -0.01838965 -0.29829195\n",
      "  0.21261044 -0.12854063  0.23627947 -0.0527148  -0.10729015 -0.09475617\n",
      "  0.25341044  0.35992845  0.25151175 -0.06308014  0.08438299  0.09130324\n",
      "  0.06944239  0.08524597 -0.05511544  0.006812    0.12832264 -0.25335437\n",
      "  0.28565276  0.1346005  -0.29505207 -0.30235587 -0.04388043  0.4207981\n",
      "  0.01130169]\n",
      "Gradient Descent(23/29): loss=0.37636439565614654, weights = [-0.26841166  0.05978326 -0.01113294 -0.23525283 -0.01577538 -0.29842742\n",
      "  0.214552   -0.12872182  0.2371236  -0.05222867 -0.1076588  -0.09467431\n",
      "  0.24855689  0.35978106  0.24958751 -0.06083446  0.07750891  0.09342007\n",
      "  0.06584921  0.07873483 -0.05006706  0.00595027  0.12455014 -0.25360385\n",
      "  0.28563912  0.1345738  -0.29506855 -0.3025522  -0.04403199  0.42064806\n",
      "  0.01082997]\n",
      "Gradient Descent(24/29): loss=0.37348508992904833, weights = [-0.27303689  0.05872423 -0.01947973 -0.23508844 -0.01333439 -0.2985661\n",
      "  0.2164569  -0.1289057   0.23799177 -0.05170281 -0.10801436 -0.09458658\n",
      "  0.24383035  0.35963061  0.24779888 -0.05861129  0.07118779  0.09562248\n",
      "  0.06249085  0.07273596 -0.04525051  0.00520449  0.12084867 -0.25380485\n",
      "  0.28568696  0.13462373 -0.29500923 -0.30275113 -0.04418656  0.42049479\n",
      "  0.01032342]\n",
      "Gradient Descent(25/29): loss=0.37092449091664687, weights = [-0.2771996   0.05768483 -0.02743328 -0.23481702 -0.01105475 -0.29870671\n",
      "  0.21832855 -0.12909103  0.23886824 -0.05114136 -0.10835966 -0.09450747\n",
      "  0.23923337  0.35947837  0.24613635 -0.05642166  0.06537484  0.09788464\n",
      "  0.05934491  0.06720922 -0.04065137  0.00456055  0.11721622 -0.25396291\n",
      "  0.2857863   0.13473868 -0.29488565 -0.30295124 -0.04434289  0.42033956\n",
      "  0.0097867 ]\n",
      "Gradient Descent(26/29): loss=0.3686385586914364, weights = [-0.28094604  0.05666423 -0.03502344 -0.23446542 -0.00892543 -0.29884836\n",
      "  0.22016975 -0.12927694  0.23974094 -0.05054805 -0.10869655 -0.0944471\n",
      "  0.23476731  0.35932521  0.24459093 -0.05427419  0.06002894  0.10018664\n",
      "  0.05639187  0.06211762 -0.03625634  0.00400591  0.11365124 -0.25408295\n",
      "  0.28592858  0.1349086  -0.2947078  -0.30315149 -0.04450008  0.42018328\n",
      "  0.00922417]\n",
      "Gradient Descent(27/29): loss=0.36659040646620433, weights = [-0.28431784  0.05566208 -0.04227619 -0.23405517 -0.00693622 -0.29899043\n",
      "  0.22198282 -0.12946283  0.24060071 -0.04992624 -0.10902619 -0.09441227\n",
      "  0.23043255  0.35917177  0.24315421 -0.05217555  0.05511229  0.10251312\n",
      "  0.05361468  0.05742701 -0.03205309  0.0035295   0.11015251 -0.25416931\n",
      "  0.28610643  0.13512476 -0.29448433 -0.30335114 -0.04465752  0.42002658\n",
      "  0.00863981]\n",
      "Gradient Descent(28/29): loss=0.3647489621312672, weights = [-0.28735245  0.05467838 -0.04921435 -0.2336035  -0.00507771 -0.29913248\n",
      "  0.22376968 -0.12964827  0.24144074 -0.04927902 -0.10934927 -0.09440733\n",
      "  0.2262287   0.35901847  0.24181833 -0.05013078  0.05059019  0.10485228\n",
      "  0.05099838  0.05310592 -0.02803028  0.0031215   0.10671904 -0.25422584\n",
      "  0.28631349  0.13537964 -0.29422273 -0.30354964 -0.0448148   0.41986989\n",
      "  0.0080373 ]\n",
      "Gradient Descent(29/29): loss=0.3630879203825716, weights = [-0.29008361  0.05371336 -0.05585813 -0.23312422 -0.00334125 -0.29927425\n",
      "  0.22553196 -0.12983302  0.2422561  -0.04860925 -0.10966611 -0.0944348\n",
      "  0.22215477  0.35886557  0.24057595 -0.04814357  0.04643076  0.10719502\n",
      "  0.04852984  0.0491253  -0.0241774   0.00277324  0.10334997 -0.25425596\n",
      "  0.28654433  0.13566669 -0.29392948 -0.30374662 -0.04497163  0.41971351\n",
      "  0.00741997]\n"
     ]
    }
   ],
   "source": [
    "w_initial = np.random.rand(num_features)\n",
    "max_iters = 30\n",
    "gamma = 0.1\n",
    "\n",
    "weights, loss = least_squares_GD (y, tx, w_initial, max_iters, gamma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yUQybl2IEndu"
   },
   "source": [
    "## Generate predictions and save ouput in csv format for submission:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ewy_ZY2kEndx"
   },
   "outputs": [],
   "source": [
    "DATA_TEST_PATH = 'data/test.csv'\n",
    "_, tX_test, ids_test = load_csv_data(DATA_TEST_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 198
    },
    "colab_type": "code",
    "id": "Ya9xiZufEnd2",
    "outputId": "a5f1377a-08a2-4255-b58d-9a733eff30fa"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-1a5e51a4d3eb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mOUTPUT_PATH\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m''\u001b[0m \u001b[0;31m# TODO: fill in desired name of output file for submission\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mcreate_csv_submission\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mids_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOUTPUT_PATH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'weights' is not defined"
     ]
    }
   ],
   "source": [
    "OUTPUT_PATH = 'data/submission.csv'\n",
    "y_pred = predict_labels(weights, tX_test)\n",
    "create_csv_submission(ids_test, y_pred, OUTPUT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ArUSTzDsEnd8"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "colab": {
   "collapsed_sections": [],
   "name": "project1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
