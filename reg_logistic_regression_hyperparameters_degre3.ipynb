{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from proj1_helpers import *\n",
    "from data_helpers import *\n",
    "from cross_validation import *\n",
    "from plots import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LOAD TRAINING DATA\n",
    "DATA_TRAIN_PATH = 'data/train.csv'\n",
    "y, tX, ids = load_csv_data(DATA_TRAIN_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4, 5, 6, 12, 26, 27, 28]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#CLEAN TRAINING DATA\n",
    "bounds = [0.0, 0.5]\n",
    "tx_clean, ind_remov = treat_undefined_values(bounds, tX)\n",
    "ind_remov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MODEL BUILDING\n",
    "tx, mean, std = standardize(tx_clean,0)\n",
    "tx_augmented = build_poly_all_features(tx,3)\n",
    "y,tx = build_model_data(tx_augmented,y)\n",
    "y = classify(y)\n",
    "num_samples = len(y)\n",
    "num_features = tx.shape[1]\n",
    "y = y.reshape(num_samples,1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(250000, 70)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_samples, num_features\n",
    "tx.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from compute_gradient import *\n",
    "from cost import *\n",
    "from implementations import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((250000, 70), (250000, 1), array([[1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        ...,\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.]]))"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Initial weight\n",
    "\n",
    "\n",
    "#Maximum iterations through the whole set\n",
    "max_iter = 100\n",
    "\n",
    "#0.001 nan\n",
    "#0.0005 nan\n",
    "\n",
    "#Step-size\n",
    "gammas = np.logspace(-6,-1, 7)\n",
    "lambdas = np.logspace (-5,-1,7)\n",
    "\n",
    "\n",
    "#Regularization factor\n",
    "# lambda_ = 0.01 142000 loss 10 000 iters\n",
    "#lambda_ = 0.001 141000 loss 10 000 iters\n",
    "#lambda_ = 0.02\n",
    "#loss_min = np.inf\n",
    "tx.shape,y.shape,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Sofia/Desktop/ML_Project1/cost.py:20: RuntimeWarning: divide by zero encountered in log\n",
      "  loss = y.T.dot(np.log(pred)) + (1 - y).T.dot(np.log(1 - pred))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nan\n",
      "nan\n",
      "0.0\n",
      "0.0\n",
      "nan\n",
      "nan\n",
      "0.0\n",
      "0.0\n",
      "nan\n",
      "nan\n",
      "0.0\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "losses_tr = np.zeros((len(gammas),len(lambdas)))\n",
    "losses_val = np.zeros((len(gammas),len(lambdas)))\n",
    "\n",
    "k_fold = 2\n",
    "seed = 1\n",
    "loss_min = np.inf\n",
    "initial_w = np.zeros((tx.shape[1],1))\n",
    "\n",
    "#CHOOSE LAMBDA AND GAMMA\n",
    "for ind_lambda, lambda_ in enumerate(lambdas):\n",
    "    for ind_gamma ,gamma_ in enumerate (gammas):\n",
    "        loss_training = 0\n",
    "        loss_validation = 0\n",
    "        training_accuracy = 0\n",
    "        validation_accuracy = 0\n",
    "        for i,k in enumerate(range(k_fold)):\n",
    "            \n",
    "            tx_train, y_train, tx_val, y_val = cross_validation(y, tx, k, k_fold, seed)\n",
    "            w, loss_train_k = reg_logistic_regression(y_train, tx_train, lambda_, initial_w, max_iter, gamma_)\n",
    "            loss_val_k = reg_logistic_loss (y_val,tx_val,w,lambda_)/len(y_val)\n",
    "            loss_train_k /= len(y_train)\n",
    "            loss_training += loss_train_k\n",
    "            loss_validation += loss_val_k\n",
    "        \n",
    "        \n",
    "        training_accuracy /= k_fold\n",
    "        validation_accuracy /= k_fold\n",
    "        loss_training /= k_fold\n",
    "        loss_validation /= k_fold\n",
    "        print(loss_training)\n",
    "        print(loss_validation)\n",
    "        print(training_accuracy)\n",
    "        print(validation_accuracy)\n",
    "        if (loss_validation < loss_min):\n",
    "            weights_star = w\n",
    "            lambda_star = lambda_\n",
    "            gamma_star = gamma_\n",
    "            loss_min = loss_validation\n",
    "        \n",
    "        losses_tr[ind_lambda][ind_gamma] = loss_training\n",
    "        losses_val[ind_lambda][ind_gamma] = loss_validation\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.00000000e-05, 4.64158883e-05, 2.15443469e-04, 1.00000000e-03,\n",
       "       4.64158883e-03, 2.15443469e-02, 1.00000000e-01])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lambdas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.00000000e-06, 6.81292069e-06, 4.64158883e-05, 3.16227766e-04,\n",
       "       2.15443469e-03, 1.46779927e-02, 1.00000000e-01])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gammas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.69319692,        inf,        nan,        nan,        nan,\n",
       "                nan,        nan],\n",
       "        [       nan,        nan,        nan,        nan,        nan,\n",
       "                nan,        nan],\n",
       "        [       nan,        nan,        nan,        nan,        nan,\n",
       "                nan,        nan],\n",
       "        [       nan,        nan,        nan,        nan,        nan,\n",
       "                nan,        nan],\n",
       "        [       nan,        nan,        nan,        nan,        nan,\n",
       "                nan,        nan],\n",
       "        [       nan,        nan,        nan,        nan,        nan,\n",
       "                nan,        nan],\n",
       "        [       nan,        nan,        nan,        nan,        nan,\n",
       "                nan,        nan]]),\n",
       " array([[0.69288124, 0.69210063,        nan,        nan,        nan,\n",
       "                nan,        nan],\n",
       "        [       nan,        nan,        nan,        nan,        nan,\n",
       "                nan,        nan],\n",
       "        [       nan,        nan,        nan,        nan,        nan,\n",
       "                nan,        nan],\n",
       "        [       nan,        nan,        nan,        nan,        nan,\n",
       "                nan,        nan],\n",
       "        [       nan,        nan,        nan,        nan,        nan,\n",
       "                nan,        nan],\n",
       "        [       nan,        nan,        nan,        nan,        nan,\n",
       "                nan,        nan],\n",
       "        [       nan,        nan,        nan,        nan,        nan,\n",
       "                nan,        nan]]))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "losses_tr, losses_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6921006315995246, 1e-05, 6.8129206905796085e-06)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_min, lambda_star, gamma_star"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "61.3084"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#PREDICT TRAINING ACCURACY\n",
    "y_pred_training = predict_labels(weights_star, tx,'logistic')\n",
    "count = 0\n",
    "for i in range(num_samples):\n",
    "    if (y_pred_training[i] == -1 and y[i] == 0):\n",
    "        count += 1\n",
    "    elif (y_pred_training[i] == y[i]):\n",
    "        count += 1\n",
    "accuracy_training = (count *100) / num_samples\n",
    "\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LOAD TEST SET\n",
    "DATA_TEST_PATH = 'data/test.csv'\n",
    "ytest, tX_test, ids_test = load_csv_data(DATA_TEST_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(568238, 23)"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#CLEAN AND STANDARDIZE TEST SET\n",
    "tX_test_clean = np.delete(tX_test, ind_remov, axis=1)\n",
    "tX_test_clean.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(568238, 23)"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tx_test_clean = remove_undefined_values (tX_test_clean)\n",
    "tx_test_clean.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "tx_test_clean, _, _ = standardize(tx_test_clean,0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(568238, 23)"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tx_test_augmented = build_poly_all_features(tx_test_clean,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(568238, 46)"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tx_test_augmented.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "#BUILD TEST MODEL\n",
    "ytest, tx_test = build_model_data(tx_test_augmented,ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PREDICT LABELS\n",
    "OUTPUT_PATH = 'data/submission_reg_logistic-degre3.csv'\n",
    "y_pred = predict_labels(weights_star, tx_test,'logistic')\n",
    "create_csv_submission(ids_test, y_pred, OUTPUT_PATH)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
